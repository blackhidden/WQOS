"""
æ“ä½œç¬¦ç®¡ç†æ¨¡å— (Operator Manager)
ä½œè€…ï¼še.e.
æ—¥æœŸï¼š2025å¹´9æœˆ

ä»machine_lib_ee.pyè¿ç§»çš„æ“ä½œç¬¦ç›¸å…³åŠŸèƒ½ï¼š
- æ“ä½œç¬¦å®šä¹‰å’Œè·å–
- ä¼šè¯åˆå§‹åŒ–
- æ“ä½œç¬¦è¿‡æ»¤
"""

import os
import time
import pandas as pd
import logging as logger

from .config_utils import load_digging_config

# æ“ä½œç¬¦å®šä¹‰
basic_ops = ["log", "sqrt", "reverse", "inverse", "rank", "zscore", "log_diff", "s_log_1p",
             'fraction', 'quantile', "normalize", "scale_down"]

ts_ops = ["ts_rank", "ts_zscore", "ts_delta", "ts_sum", "ts_product",
          "ts_ir", "ts_std_dev", "ts_mean", "ts_arg_min", "ts_arg_max", "ts_min_diff",
          "ts_max_diff", "ts_returns", "ts_scale", "ts_skewness", "ts_kurtosis",
          "ts_quantile"]

ts_not_use = ["ts_min", "ts_max", "ts_delay", "ts_median", ]

arsenal = ["ts_moment", "ts_entropy", "ts_min_max_cps", "ts_min_max_diff", "inst_tvr", 'sigmoid',
           "ts_decay_exp_window", "ts_percentage", "vector_neut", "vector_proj", "signed_power"]

twin_field_ops = ["ts_corr", "ts_covariance", "ts_co_kurtosis", "ts_co_skewness", "ts_theilsen"]

group_ops = ["group_neutralize", "group_rank", "group_normalize", "group_scale", "group_zscore"]

group_ac_ops = ["group_sum", "group_max", "group_mean", "group_median", "group_min", "group_std_dev", ]

vec_ops = ["vec_avg", "vec_sum", "vec_ir", "vec_max",
                   "vec_count", "vec_skewness", "vec_stddev", "vec_choose"]

ops_set = basic_ops + ts_ops + arsenal + group_ops

# å…¨å±€ä¼šè¯å˜é‡ï¼ˆä¸åŸmachine_lib_eeä¿æŒå…¼å®¹ï¼‰
s = None


def init_session():
    """åˆå§‹åŒ–sessionï¼Œè·å–å¯ç”¨çš„æ“ä½œç¬¦"""
    global s, ts_ops, basic_ops, group_ops, vec_ops
    if s is None:
        try:
            # ä½¿ç”¨SessionClientè·å–ä¼šè¯
            from sessions.session_client import get_session
            s = get_session()
            logger.info("âœ… operator_manager ä½¿ç”¨SessionClient")
        except Exception as e:
            logger.warning(f"âŒ SessionClientä¸å¯ç”¨: {e}")
            logger.warning("ğŸ’¡ è¯·ç¡®ä¿SessionKeeperæ­£åœ¨è¿è¡Œå¹¶ç»´æŠ¤æœ‰æ•ˆä¼šè¯")
            raise
        
        # ä¿å­˜åŸå§‹æ“ä½œç¬¦åˆ—è¡¨
        globals()['ts_ops_original'] = ts_ops.copy()
        globals()['basic_ops_original'] = basic_ops.copy()
        globals()['group_ops_original'] = group_ops.copy()
        globals()['vec_ops_original'] = vec_ops.copy()
        
        # è·å–é…ç½®ä¸­çš„é‡è¯•å‚æ•°
        try:
            config = load_digging_config()
            max_retries = config.get('api_max_retries', 3)
            retry_delay = config.get('api_retry_delay', 5)
            use_backoff = config.get('api_rate_limit_backoff', True)
        except:
            # å¦‚æœé…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
            max_retries = 3
            retry_delay = 5
            use_backoff = True
        
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ” è·å–å¯ç”¨æ“ä½œç¬¦ (å°è¯• {attempt + 1}/{max_retries})...")
                res = s.get("https://api.worldquantbrain.com/operators")
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                if res.status_code != 200:
                    logger.warning(f"âš ï¸  API è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {res.status_code}")
                    if attempt < max_retries - 1:
                        logger.info(f"â³ ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                        time.sleep(retry_delay)
                        continue
                    else:
                        logger.warning("âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨é»˜è®¤æ“ä½œç¬¦åˆ—è¡¨")
                        # ç¡®ä¿å…¨å±€å˜é‡è¢«æ­£ç¡®è®¾ç½®
                        globals()['vec_ops'] = vec_ops
                        return s
                
                # è§£æå“åº”
                response_data = res.json()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯å“åº”
                if isinstance(response_data, dict) and 'message' in response_data:
                    error_msg = response_data['message']
                    logger.warning(f"âš ï¸  API è¿”å›é”™è¯¯: {error_msg}")
                    
                    if 'rate limit' in error_msg.lower():
                        if attempt < max_retries - 1:
                            if use_backoff:
                                wait_time = retry_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                                logger.info(f"ğŸš« é‡åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯• (æŒ‡æ•°é€€é¿)...")
                            else:
                                wait_time = retry_delay
                                logger.info(f"ğŸš« é‡åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                            time.sleep(wait_time)
                            continue
                        else:
                            logger.warning("âŒ é€Ÿç‡é™åˆ¶æŒç»­å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æ“ä½œç¬¦åˆ—è¡¨")
                            # ç¡®ä¿å…¨å±€å˜é‡è¢«æ­£ç¡®è®¾ç½®
                            globals()['vec_ops'] = vec_ops
                            return s
                    else:
                        logger.warning(f"âŒ API é”™è¯¯: {error_msg}")
                        if attempt < max_retries - 1:
                            logger.info(f"â³ ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                            time.sleep(retry_delay)
                            continue
                        else:
                            logger.warning("âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨é»˜è®¤æ“ä½œç¬¦åˆ—è¡¨")
                            # ç¡®ä¿å…¨å±€å˜é‡è¢«æ­£ç¡®è®¾ç½®
                            globals()['vec_ops'] = vec_ops
                            return s
                
                # æ­£å¸¸å“åº”ï¼Œæ„é€  DataFrame
                if isinstance(response_data, list) and len(response_data) > 0:
                    aval = pd.DataFrame(response_data)['name'].tolist()
                    
                    # è¿‡æ»¤æ‰€æœ‰æ“ä½œç¬¦ç±»å‹
                    original_ts = len(ts_ops)
                    original_basic = len(basic_ops)
                    original_group = len(group_ops)
                    original_vec = len(vec_ops)
                    
                    ts_ops = [op for op in ts_ops if op in aval]
                    basic_ops = [op for op in basic_ops if op in aval]
                    group_ops = [op for op in group_ops if op in aval]
                    vec_ops = [op for op in vec_ops if op in aval]
                    
                    # æ›´æ–°å…¨å±€å˜é‡
                    globals()['ts_ops'] = ts_ops
                    globals()['basic_ops'] = basic_ops  
                    globals()['group_ops'] = group_ops
                    globals()['vec_ops'] = vec_ops
                    
                    logger.info(f"âœ… æˆåŠŸè·å– {len(aval)} ä¸ªå¯ç”¨æ“ä½œç¬¦")
                    logger.info(f"ğŸ“Š æ—¶é—´åºåˆ—æ“ä½œç¬¦: {len(ts_ops)}/{original_ts} ä¸ª")
                    logger.info(f"ğŸ“Š åŸºç¡€æ“ä½œç¬¦: {len(basic_ops)}/{original_basic} ä¸ª")
                    logger.info(f"ğŸ“Š ç»„æ“ä½œç¬¦: {len(group_ops)}/{original_group} ä¸ª")
                    logger.info(f"ğŸ“Š å‘é‡æ“ä½œç¬¦: {len(vec_ops)}/{original_vec} ä¸ª")
                    
                    # æ˜¾ç¤ºè¢«è¿‡æ»¤æ‰çš„æ“ä½œç¬¦
                    ts_ops_orig = globals().get('ts_ops_original', [])
                    basic_ops_orig = globals().get('basic_ops_original', [])
                    group_ops_orig = globals().get('group_ops_original', [])
                    vec_ops_orig = globals().get('vec_ops_original', [])
                    
                    filtered_ts = [op for op in ts_ops_orig if op not in aval]
                    filtered_basic = [op for op in basic_ops_orig if op not in aval] 
                    filtered_group = [op for op in group_ops_orig if op not in aval]
                    filtered_vec = [op for op in vec_ops_orig if op not in aval]
                    
                    if filtered_ts or filtered_basic or filtered_group or filtered_vec:
                        logger.info(f"âš ï¸  è¿‡æ»¤æ‰çš„ä¸å¯ç”¨æ“ä½œç¬¦:")
                        if filtered_ts:
                            logger.info(f"   ts_ops: {filtered_ts}")
                        if filtered_basic:
                            logger.info(f"   basic_ops: {filtered_basic}")
                        if filtered_group:
                            logger.info(f"   group_ops: {filtered_group}")
                        if filtered_vec:
                            logger.info(f"   vec_ops: {filtered_vec}")
                    
                    break
                else:
                    logger.warning("âš ï¸  API è¿”å›ç©ºæ•°æ®æˆ–æ ¼å¼å¼‚å¸¸")
                    if attempt < max_retries - 1:
                        logger.info(f"â³ ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                        time.sleep(retry_delay)
                        continue
                    else:
                        logger.warning("âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨é»˜è®¤æ“ä½œç¬¦åˆ—è¡¨")
                        # ç¡®ä¿å…¨å±€å˜é‡è¢«æ­£ç¡®è®¾ç½®
                        globals()['vec_ops'] = vec_ops
                        return s
                        
            except Exception as e:
                logger.warning(f"âŒ è·å–æ“ä½œç¬¦æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                if attempt < max_retries - 1:
                    logger.info(f"â³ ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
                    continue
                else:
                    logger.warning("âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨é»˜è®¤æ“ä½œç¬¦åˆ—è¡¨")
                    # ç¡®ä¿å…¨å±€å˜é‡è¢«æ­£ç¡®è®¾ç½®
                    globals()['vec_ops'] = vec_ops
                    return s
    
    return s


def get_available_ops():
    """è·å–å¯ç”¨çš„æ“ä½œç¬¦åˆ—è¡¨"""
    init_session()
    global group_ops, twin_field_ops, vec_ops, arsenal, aval
    if 'aval' not in globals():
        try:
            res = s.get("https://api.worldquantbrain.com/operators")
            if res.status_code == 200:
                response_data = res.json()
                if isinstance(response_data, list) and len(response_data) > 0:
                    aval = pd.DataFrame(response_data)['name'].tolist()
                    group_ops = [op for op in group_ops if op in aval]
                    twin_field_ops = [op for op in twin_field_ops if op in aval]
                else:
                    logger.warning("âš ï¸  get_available_ops: API è¿”å›ç©ºæ•°æ®ï¼Œä½¿ç”¨é»˜è®¤æ“ä½œç¬¦")
                    aval = []
            else:
                logger.warning(f"âš ï¸  get_available_ops: API è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {res.status_code}")
                aval = []
        except Exception as e:
            logger.warning(f"âš ï¸  get_available_ops: è·å–æ“ä½œç¬¦å¼‚å¸¸: {e}")
            aval = []
        arsenal = [op for op in arsenal if op in aval]
        vec_ops = [op for op in vec_ops if op in aval]
        # æ›´æ–°å…¨å±€å˜é‡
        globals()['vec_ops'] = vec_ops
    return aval


def get_vec_fields(fields):
    """ç”Ÿæˆå‘é‡æ“ä½œç¬¦å­—æ®µåˆ—è¡¨"""
    vec_fields = []

    for field in fields:
        for vec_op in vec_ops:
            if vec_op == "vec_choose":
                vec_fields.append("%s(%s, nth=-1)" % (vec_op, field))
                vec_fields.append("%s(%s, nth=0)" % (vec_op, field))
            else:
                vec_fields.append("%s(%s)" % (vec_op, field))

    return vec_fields


def list_chuckation(field_list, num):
    """å°†åˆ—è¡¨åˆ†å—"""
    list_chucked = []
    lens = len(field_list)
    i = 0
    while i + num <= lens:
        list_chucked.append(field_list[i:i + num])
        i += num
    list_chucked.append(field_list[i:lens])
    return list_chucked
