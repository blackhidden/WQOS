"""
äºŒé˜¶æŒ–æ˜æ‰§è¡Œå™¨ (Second Order Executor)
ä½œè€…ï¼še.e.
æ—¥æœŸï¼š2025.09.05

è´Ÿè´£æ‰§è¡ŒäºŒé˜¶å› å­æŒ–æ˜ï¼ŒåŒ…æ‹¬ï¼š
- åŸºäºä¸€é˜¶ç¬¦åˆæ¡ä»¶å› å­ç”ŸæˆäºŒé˜¶å› å­
- æŒç»­ç›‘æ§ä¸€é˜¶æŒ–æ˜äº§å‡º
- è¿›åº¦è·Ÿè¸ª
- æ¨¡æ‹Ÿæ‰§è¡Œ
"""

import os
import sys
from collections import defaultdict
from typing import List, Dict, Tuple

from .base_executor import BaseExecutor

try:
    from machine_lib_ee import (
        get_alphas, transform, get_group_second_order_factory
    )
    from digging.utils.common_utils import get_filtered_operators
except ImportError:
    sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))
    from machine_lib_ee import (
        get_alphas, transform, get_group_second_order_factory
    )
    from digging.utils.common_utils import get_filtered_operators


class SecondOrderExecutor(BaseExecutor):
    """äºŒé˜¶æŒ–æ˜æ‰§è¡Œå™¨ - è´Ÿè´£æ‰§è¡ŒäºŒé˜¶å› å­æŒ–æ˜çš„å®Œæ•´æµç¨‹"""
    
    def get_stage_number(self) -> int:
        """è·å–æ‰§è¡Œå™¨å¯¹åº”çš„é˜¶æ®µå·"""
        return 2
    
    def get_qualified_first_order_factors(self) -> Tuple[List[str], List[str], int]:
        """è·å–ç¬¦åˆæ¡ä»¶çš„ä¸€é˜¶å› å­
        
        Returns:
            Tuple[List[str], List[str], int]: (nextå› å­åˆ—è¡¨, decayå› å­åˆ—è¡¨, æ€»æ•°é‡)
        """
        step1_tag = self.config_manager.generate_tag(self.current_dataset, 1)
        
        # è·å–ç¬¦åˆæ¡ä»¶çš„ä¸€é˜¶å› å­
        fo_tracker = get_alphas("2024-10-07", "2025-12-31",
                               0.75, 0.5, 100, 100,
                               self.config_manager.region, 
                               self.config_manager.universe, 
                               self.config_manager.delay, 
                               "EQUITY",
                               500, "track", tag=step1_tag)
        
        next_factors = fo_tracker.get('next', [])
        decay_factors = fo_tracker.get('decay', [])
        total_qualified = len(next_factors) + len(decay_factors)
        
        return next_factors, decay_factors, total_qualified
    
    def generate_second_order_factors(self, next_factors: List[str], decay_factors: List[str]) -> List[Tuple[str, int]]:
        """ç”ŸæˆäºŒé˜¶å› å­åˆ—è¡¨
        
        Args:
            next_factors: nextç±»å‹çš„ä¸€é˜¶å› å­
            decay_factors: decayç±»å‹çš„ä¸€é˜¶å› å­
            
        Returns:
            List[Tuple[str, int]]: äºŒé˜¶å› å­è¡¨è¾¾å¼å’Œè¡°å‡å€¼çš„å…ƒç»„åˆ—è¡¨
        """
        # è½¬æ¢ä¸€é˜¶å› å­æ ¼å¼
        fo_layer = transform(next_factors + decay_factors)
        
        # è·å–è¿‡æ»¤åçš„æ“ä½œç¬¦
        ts_ops, basic_ops, group_ops = get_filtered_operators()
        
        # ç”ŸæˆäºŒé˜¶å› å­
        second_order_factors = []
        self.logger.info(f"è¯·æ„å»ºäºŒé˜¶å› å­è¡¨è¾¾å¼")
        
        if self.logger:
            self.logger.info(f"ğŸ“Š ç”ŸæˆäºŒé˜¶å› å­: {len(second_order_factors):,} ä¸ª")
        
        return second_order_factors
    
    def filter_completed_second_order_factors(self, all_factors: List[Tuple[str, int]]) -> List[Tuple[str, int]]:
        """è¿‡æ»¤å·²å®Œæˆçš„äºŒé˜¶å› å­
        
        Args:
            all_factors: æ‰€æœ‰äºŒé˜¶å› å­åˆ—è¡¨
            
        Returns:
            List[Tuple[str, int]]: å¾…å¤„ç†çš„äºŒé˜¶å› å­åˆ—è¡¨
        """
        completed_expressions = self.progress_tracker.get_completed_expressions(
            self.current_dataset, step=2
        )
        
        valid_factors = [alpha_decay for alpha_decay in all_factors 
                        if alpha_decay[0] not in completed_expressions]
        
        completion_rate = len(completed_expressions) / len(all_factors) * 100 if all_factors else 0
        
        if self.logger:
            self.progress_tracker.log_progress_summary(
                self.current_dataset, 2, len(completed_expressions), 
                len(all_factors), completion_rate
            )
        
        return valid_factors
    
    async def execute_second_order_batch(self, valid_factors: List[Tuple[str, int]]) -> List[Dict]:
        """æ‰§è¡ŒäºŒé˜¶å› å­æ¨¡æ‹Ÿæ‰¹æ¬¡
        
        Args:
            valid_factors: å¾…å¤„ç†çš„äºŒé˜¶å› å­åˆ—è¡¨
            
        Returns:
            List[Dict]: æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        if not valid_factors:
            return []
        
        # åˆ†ç¦»Alphaè¡¨è¾¾å¼å’Œè¡°å‡å€¼
        alpha_list = [alpha_decay[0] for alpha_decay in valid_factors]
        decay_list = [alpha_decay[1] for alpha_decay in valid_factors]
        
        # å‡†å¤‡å…¶ä»–å‚æ•°
        region_list = [(self.config_manager.region, self.config_manager.universe)] * len(alpha_list)
        delay_list = [self.config_manager.delay] * len(alpha_list)
        stone_bag = []
        step2_tag = self.config_manager.generate_tag(self.current_dataset, 2)
        
        # æ‰§è¡Œæ¨¡æ‹Ÿ
        await self.simulation_engine.simulate_multiple_alphas(
            alpha_list, region_list, decay_list, delay_list,
            step2_tag, self.config_manager.neutralization, stone_bag, 
            self.config_manager.get_n_jobs_config()
        )
        
        return [{'alpha': alpha, 'tag': step2_tag} for alpha in alpha_list]
    
    async def run_continuous_monitoring(self, retry_count: int = 0) -> List[Dict]:
        """è¿è¡ŒæŒç»­ç›‘æ§æ¨¡å¼ï¼ˆé€’å½’ç›‘æ§ä¸€é˜¶æŒ–æ˜äº§å‡ºï¼‰
        
        Args:
            retry_count: é‡è¯•è®¡æ•°
            
        Returns:
            List[Dict]: æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        all_results = []
        
        while True:
            try:
                # 1. è·å–ç¬¦åˆæ¡ä»¶çš„ä¸€é˜¶å› å­
                next_factors, decay_factors, total_qualified = self.get_qualified_first_order_factors()
                
                if self.logger:
                    self.logger.info(f"ğŸ“Š ç¬¦åˆæ¡ä»¶ä¸€é˜¶å› å­: next{len(next_factors):,}ä¸ª + decay{len(decay_factors):,}ä¸ª = æ€»è®¡{total_qualified:,}ä¸ª")
                
                if total_qualified == 0:
                    total_wait_hours = retry_count + 1
                    if self.logger:
                        self.logger.warning(f"âš ï¸  æš‚æ— ç¬¦åˆæ¡ä»¶çš„ä¸€é˜¶å› å­ (ç¬¬{retry_count + 1}æ¬¡æ£€æŸ¥ï¼Œå·²ç­‰å¾…{retry_count}å°æ—¶)")
                        self.logger.info(f"ğŸ”„ äºŒé˜¶æŒ–æ˜æŒç»­ç­‰å¾…ä¸€é˜¶æŒ–æ˜äº§ç”Ÿç¬¦åˆæ¡ä»¶çš„å› å­...")
                        self.logger.info(f"ğŸ’¡ è¿™æ˜¯æ­£å¸¸ç°è±¡ï¼šäºŒé˜¶æŒ–æ˜ä¾èµ–ä¸€é˜¶æŒ–æ˜çš„è¾“å‡ºï¼Œéœ€è¦è€å¿ƒç­‰å¾…")
                    
                    await self.simulation_engine.sleep_with_countdown(3600, "ç­‰å¾…ä¸€é˜¶æŒ–æ˜äº§ç”Ÿæ›´å¤šå› å­")
                    retry_count += 1
                    continue
                
                # 2. ç”ŸæˆäºŒé˜¶å› å­
                second_order_factors = self.generate_second_order_factors(next_factors, decay_factors)
                
                # 3. è¿‡æ»¤å·²å®Œæˆçš„äºŒé˜¶å› å­
                valid_factors = self.filter_completed_second_order_factors(second_order_factors)
                
                if not valid_factors:
                    if self.logger:
                        self.logger.info(f"âœ… æ•°æ®é›† {self.current_dataset} äºŒé˜¶æŒ–æ˜å½“å‰æ‰¹æ¬¡å·²å®Œæˆ")
                        self.logger.info(f"ğŸ”„ ç»§ç»­ç›‘æ§ä¸€é˜¶æŒ–æ˜ï¼Œç­‰å¾…æ–°çš„ç¬¦åˆæ¡ä»¶å› å­...")
                    
                    await self.simulation_engine.sleep_with_countdown(1800, "ç­‰å¾…ä¸€é˜¶æŒ–æ˜äº§ç”Ÿæ–°çš„ç¬¦åˆæ¡ä»¶å› å­")  # 30åˆ†é’Ÿ
                    retry_count += 1
                    continue
                
                # 4. æ‰§è¡ŒäºŒé˜¶æŒ–æ˜
                batch_results = await self.execute_second_order_batch(valid_factors)
                all_results.extend(batch_results)
                
                if self.logger:
                    self.logger.info(f"âœ… äºŒé˜¶æŒ–æ˜æ‰¹æ¬¡å®Œæˆ: {len(batch_results):,}ä¸ªå› å­")
                
                # å®Œæˆå½“å‰æ‰¹æ¬¡åï¼Œç»§ç»­ç›‘æ§æ–°çš„ç¬¦åˆæ¡ä»¶å› å­
                if self.logger:
                    self.logger.info(f"ğŸ”„ å½“å‰æ‰¹æ¬¡å®Œæˆï¼Œç»§ç»­ç›‘æ§ä¸€é˜¶æŒ–æ˜äº§ç”Ÿæ–°çš„ç¬¦åˆæ¡ä»¶å› å­...")
                
                await self.simulation_engine.sleep_with_countdown(1800, "ç­‰å¾…ä¸€é˜¶æŒ–æ˜äº§ç”Ÿæ–°çš„ç¬¦åˆæ¡ä»¶å› å­")  # 30åˆ†é’Ÿ
                retry_count += 1
                
            except KeyboardInterrupt:
                if self.logger:
                    self.logger.info(f"âš ï¸  ç”¨æˆ·ä¸­æ–­ï¼ŒäºŒé˜¶æŒ–æ˜åœæ­¢")
                break
            except Exception as e:
                if self.logger:
                    self.logger.error(f"âŒ äºŒé˜¶æŒ–æ˜ç›‘æ§å¾ªç¯å¼‚å¸¸: {e}")
                    import traceback
                    traceback.print_exc()
                # ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
                await self.simulation_engine.sleep_with_countdown(300, "å¼‚å¸¸æ¢å¤ç­‰å¾…")
                retry_count += 1
        
        return all_results
    
    async def execute(self) -> List[Dict]:
        """æ‰§è¡ŒäºŒé˜¶æŒ–æ˜çš„å®Œæ•´æµç¨‹
        
        Returns:
            List[Dict]: æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        stage = self.get_stage_number()
        self.log_execution_start(stage)
        
        try:
            # 1. åˆå§‹åŒ–ä¼šè¯å’Œæ“ä½œç¬¦
            if not self.ensure_session_and_operators():
                raise Exception("ä¼šè¯å’Œæ“ä½œç¬¦åˆå§‹åŒ–å¤±è´¥")
            
            if self.logger:
                self.logger.info(f"\nğŸ”„ äºŒé˜¶æŒ–æ˜ | æ•°æ®é›†: {self.current_dataset}")
            
            # 2. è¿è¡ŒæŒç»­ç›‘æ§æ¨¡å¼
            results = await self.run_continuous_monitoring()
            
            # å‘é€å®Œæˆé€šçŸ¥
            self.send_completion_notification(stage, len(results))
            
            self.log_execution_end(stage, results, success=True)
            return results
            
        except Exception as e:
            self.handle_execution_error(stage, e)
            self.log_execution_end(stage, [], success=False)
            return []
