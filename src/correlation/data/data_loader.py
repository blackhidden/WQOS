"""
æ•°æ®åŠ è½½å™¨ - è´Ÿè´£OS Alphaæ•°æ®çš„ä¸‹è½½å’ŒåŠ è½½
"""

import pickle
import pandas as pd
from typing import List, Dict, Tuple, Optional
from collections import defaultdict


class DataLoader:
    """æ•°æ®åŠ è½½å™¨"""
    
    def __init__(self, config_manager, session_service, pnl_manager, logger):
        """åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨"""
        self.config = config_manager
        self.session_service = session_service
        self.pnl_manager = pnl_manager
        self.logger = logger
        
        # æœ¬åœ°æ•°æ®ç¼“å­˜
        self.os_alpha_ids = None
        self.os_alpha_rets = None
        self.ppac_alpha_ids = []
        self.data_loaded = False
        self.current_check_type = None
    
    def save_obj(self, obj: object, name: str) -> None:
        """ä¿å­˜å¯¹è±¡åˆ°æ–‡ä»¶ä¸­ï¼Œä»¥pickleæ ¼å¼åºåˆ—åŒ–"""
        file_path = self.config.data_path / f"{name}.pickle"
        with open(file_path, 'wb') as f:
            pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)
    
    def load_obj(self, name: str) -> object:
        """ä»pickleæ–‡ä»¶ä¸­åŠ è½½å¯¹è±¡"""
        file_path = self.config.data_path / f"{name}.pickle"
        if not file_path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        with open(file_path, 'rb') as f:
            return pickle.load(f)
    
    def get_os_alphas(self, limit: int = 100, get_first: bool = False) -> List[Dict]:
        """è·å–OSé˜¶æ®µçš„alphaåˆ—è¡¨"""
        fetched_alphas = []
        offset = 0
        total_alphas = 100
        
        while len(fetched_alphas) < total_alphas:
            self.logger.info(f"ğŸ“¥ è·å–alphaåˆ—è¡¨: offset={offset}, limit={limit}")
            url = f"https://api.worldquantbrain.com/users/self/alphas?stage=OS&limit={limit}&offset={offset}&order=-dateSubmitted"
            
            try:
                response = self.session_service.wait_get(url, message=f"è·å–å·²æäº¤alphaåˆ—è¡¨")
                res = response.json()
                
                if offset == 0:
                    total_alphas = res['count']
                    self.logger.info(f"ğŸ“Š æ€»å…±æ‰¾åˆ° {total_alphas} ä¸ªOSé˜¶æ®µçš„alpha")
                
                alphas = res["results"]
                fetched_alphas.extend(alphas)
                
                if len(alphas) < limit:
                    break
                
                offset += limit
                
                if get_first:
                    break
                    
            except Exception as e:
                self.logger.error(f"âŒ è·å–alphaåˆ—è¡¨å¤±è´¥: {e}")
                break
        
        return fetched_alphas[:total_alphas]
    
    def download_data(self, flag_increment=True):
        """ä¸‹è½½å¹¶ä¿å­˜ç›¸å…³æ€§æ£€æŸ¥æ‰€éœ€çš„æ•°æ®"""
        self.logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½æ•°æ®...")
        
        # è®°å½•æ˜¯å¦æœ‰æ–°çš„å·²æäº¤Alpha
        has_new_submitted_alphas = False
        
        if flag_increment:
            try:
                os_alpha_ids = self.load_obj('os_alpha_ids')
                os_alpha_pnls = self.load_obj('os_alpha_pnls')
                ppac_alpha_ids = self.load_obj('ppac_alpha_ids')
                exist_alpha = [alpha for ids in os_alpha_ids.values() for alpha in ids]
                self.logger.info(f"ğŸ“‚ åŠ è½½ç°æœ‰æ•°æ®: {len(exist_alpha)} ä¸ªalpha")
            except Exception as e:
                self.logger.warning(f"âš ï¸ æ— æ³•åŠ è½½ç°æœ‰æ•°æ®: {e}ï¼Œé‡æ–°å¼€å§‹ä¸‹è½½")
                os_alpha_ids = None
                os_alpha_pnls = None
                exist_alpha = []
                ppac_alpha_ids = []
        else:
            os_alpha_ids = None
            os_alpha_pnls = None
            exist_alpha = []
            ppac_alpha_ids = []
        
        # è·å–alphaåˆ—è¡¨
        if os_alpha_ids is None:
            alphas = self.get_os_alphas(limit=100, get_first=False)
        else:
            alphas = self.get_os_alphas(limit=30, get_first=True)
        
        # è¿‡æ»¤æ–°alpha
        alphas = [item for item in alphas if item['id'] not in exist_alpha]
        self.logger.info(f"ğŸ“Š æ‰¾åˆ° {len(alphas)} ä¸ªæ–°alpha")
        
        if not alphas:
            self.logger.info(f"âœ… æ²¡æœ‰æ–°çš„alphaéœ€è¦ä¸‹è½½")
            return False  # è¿”å›Falseè¡¨ç¤ºæ²¡æœ‰æ–°Alpha
        
        # æœ‰æ–°Alphaï¼Œè®¾ç½®æ ‡å¿—
        has_new_submitted_alphas = True
        
        # è¯†åˆ«PPAC alpha
        new_ppac_ids = []
        for alpha in alphas:
            classifications = alpha.get('classifications', [])
            for classification in classifications:
                if isinstance(classification, dict) and classification.get('name') == 'Power Pool Alpha':
                    new_ppac_ids.append(alpha['id'])
                    break
        
        ppac_alpha_ids.extend(new_ppac_ids)
        self.logger.info(f"ğŸ”µ æ‰¾åˆ° {len(new_ppac_ids)} ä¸ªæ–°PPAC alpha")
        
        # è·å–PnLæ•°æ®
        os_alpha_ids, os_alpha_pnls = self.pnl_manager.get_alpha_pnls(alphas, alpha_pnls=os_alpha_pnls, alpha_ids=os_alpha_ids)
        
        # ä»æ•°æ®åº“ä¸­ç§»é™¤æ–°æäº¤çš„alphaï¼ˆé¿å…å’Œè‡ªå·±äº§ç”Ÿ1.0ç›¸å…³æ€§ï¼‰
        if has_new_submitted_alphas:
            new_alpha_ids = [alpha['id'] for alpha in alphas]
            self.logger.info(f"ğŸ—‘ï¸ ä»æ•°æ®åº“ä¸­ç§»é™¤ {len(new_alpha_ids)} ä¸ªæ–°æäº¤çš„Alphaï¼ˆé¿å…è‡ªç›¸å…³ï¼‰...")
            self._remove_submitted_alphas_from_database(new_alpha_ids)
        
        # ä¿å­˜æ•°æ®
        self.save_obj(os_alpha_ids, 'os_alpha_ids')
        self.save_obj(os_alpha_pnls, 'os_alpha_pnls')
        self.save_obj(ppac_alpha_ids, 'ppac_alpha_ids')
        
        self.logger.info(f'âœ… æ•°æ®ä¸‹è½½å®Œæˆ: æ–°å¢ {len(alphas)} ä¸ªalpha, æ€»è®¡ {os_alpha_pnls.shape[1]} ä¸ªalpha')
        
        return has_new_submitted_alphas  # è¿”å›æ˜¯å¦æœ‰æ–°Alpha
    
    def load_data(self, tag=None):
        """åŠ è½½æ•°æ®å¹¶æ ¹æ®æ ‡ç­¾è¿‡æ»¤"""
        try:
            os_alpha_ids = self.load_obj('os_alpha_ids')
            os_alpha_pnls = self.load_obj('os_alpha_pnls')
            ppac_alpha_ids = self.load_obj('ppac_alpha_ids')
        except FileNotFoundError as e:
            self.logger.error(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {e}")
            self.logger.info(f"ğŸ’¡ è¯·å…ˆè¿è¡Œæ•°æ®ä¸‹è½½: download_data()")
            return None, None
        
        # æ ¹æ®æ ‡ç­¾è¿‡æ»¤æ•°æ®
        if tag == 'PPAC':
            self.logger.info(f"ğŸ”µ åŠ è½½PPACç±»å‹æ•°æ®")
            for region in os_alpha_ids:
                os_alpha_ids[region] = [alpha for alpha in os_alpha_ids[region] if alpha in ppac_alpha_ids]
        elif tag == 'SelfCorr':
            self.logger.info(f"ğŸŸ¢ åŠ è½½æ™®é€šç›¸å…³æ€§æ•°æ®")
            for region in os_alpha_ids:
                os_alpha_ids[region] = [alpha for alpha in os_alpha_ids[region] if alpha not in ppac_alpha_ids]
        else:
            self.logger.info(f"ğŸ“Š åŠ è½½æ‰€æœ‰æ•°æ®")
        
        # è·å–ç°æœ‰alphaåˆ—è¡¨
        exist_alpha = [alpha for ids in os_alpha_ids.values() for alpha in ids]
        os_alpha_pnls = os_alpha_pnls[exist_alpha]
        
        # è®¡ç®—æ”¶ç›Šç‡
        os_alpha_rets = os_alpha_pnls - os_alpha_pnls.ffill().shift(1)
        
        # é™åˆ¶æ—¶é—´çª—å£
        cutoff_date = pd.to_datetime(os_alpha_rets.index).max() - pd.DateOffset(years=self.config.time_window_years)
        os_alpha_rets = os_alpha_rets[pd.to_datetime(os_alpha_rets.index) > cutoff_date]
        
        self.logger.info(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆ: {len(os_alpha_ids)} ä¸ªåŒºåŸŸ, {os_alpha_rets.shape[1]} ä¸ªalpha")
        self.logger.info(f"ğŸ“… æ—¶é—´èŒƒå›´: {os_alpha_rets.index.min()} åˆ° {os_alpha_rets.index.max()}")
        
        return os_alpha_ids, os_alpha_rets
    
    def ensure_data_loaded(self, check_type=None, force_reload=False, force_check_new=False):
        """ç¡®ä¿æ•°æ®å·²åŠ è½½"""
        # åœ¨æŒç»­ç›‘æ§æ¨¡å¼ä¸‹ï¼Œå³ä½¿æ•°æ®å·²åŠ è½½ä¹Ÿè¦æ£€æŸ¥æ–°Alpha
        if self.data_loaded and not force_reload and self.current_check_type == check_type and not force_check_new:
            self.logger.info(f"ğŸ“Š ä½¿ç”¨å·²åŠ è½½çš„æ•°æ®")
            return True, False
        
        self.logger.info(f"ğŸ“‚ åŠ è½½æ•°æ® (ç±»å‹: {check_type if check_type else 'å…¨éƒ¨'})...")
        
        try:
            # å…ˆå°è¯•ä¸‹è½½æœ€æ–°æ•°æ®ï¼ˆæ£€æŸ¥æ–°Alphaï¼‰
            has_new_alphas = self.download_data(flag_increment=True)
            
            # å¦‚æœåªæ˜¯æ£€æŸ¥æ–°Alphaè€Œæ•°æ®å·²åŠ è½½ï¼Œä¸éœ€è¦é‡æ–°åŠ è½½å…¨éƒ¨æ•°æ®
            if self.data_loaded and not force_reload and self.current_check_type == check_type:
                self.logger.info(f"ğŸ“Š æ•°æ®å·²åŠ è½½ï¼Œä»…æ£€æŸ¥æ–°Alpha")
                return True, has_new_alphas
            
            # åŠ è½½æ•°æ®
            self.os_alpha_ids, self.os_alpha_rets = self.load_data(tag=check_type)
            
            if self.os_alpha_ids is None or self.os_alpha_rets is None:
                return False, False
            
            self.current_check_type = check_type
            self.data_loaded = True
            
            return True, has_new_alphas
            
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False, False
    
    def load_local_data_only(self, check_type=None, force_reload=False):
        """ä»…åŠ è½½æœ¬åœ°æ•°æ®ï¼Œä¸è¿›è¡Œæ–°Alphaæ£€æŸ¥å’Œä¸‹è½½
        
        Args:
            check_type: æ•°æ®ç±»å‹ ("PPAC" æˆ– "SelfCorr")
            force_reload: æ˜¯å¦å¼ºåˆ¶é‡æ–°åŠ è½½
            
        Returns:
            tuple: (success, has_cached_data)
        """
        # å¦‚æœæ•°æ®å·²åŠ è½½ä¸”ç±»å‹åŒ¹é…ï¼Œç›´æ¥è¿”å›
        if self.data_loaded and not force_reload and self.current_check_type == check_type:
            self.logger.debug(f"ğŸ“Š ä½¿ç”¨å·²åŠ è½½çš„{check_type if check_type else 'å…¨éƒ¨'}æ•°æ®")
            return True, True
        
        self.logger.info(f"ğŸ“‚ ä»…åŠ è½½æœ¬åœ°{check_type if check_type else 'å…¨éƒ¨'}æ•°æ®ï¼ˆè·³è¿‡æ–°Alphaæ£€æŸ¥ï¼‰...")
        
        try:
            # ç›´æ¥åŠ è½½æœ¬åœ°æ•°æ®ï¼Œä¸è¿›è¡Œæ–°Alphaæ£€æŸ¥
            self.os_alpha_ids, self.os_alpha_rets = self.load_data(tag=check_type)
            
            if self.os_alpha_ids is None or self.os_alpha_rets is None:
                return False, False
            
            self.current_check_type = check_type
            self.data_loaded = True
            
            return True, True
            
        except Exception as e:
            self.logger.error(f"âŒ æœ¬åœ°æ•°æ®åŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False, False
    
    def _remove_submitted_alphas_from_database(self, alpha_ids: List[str]):
        """ä»æ•°æ®åº“ä¸­ç§»é™¤å·²æäº¤çš„Alphaï¼ˆé¿å…å’Œè‡ªå·±äº§ç”Ÿ1.0ç›¸å…³æ€§ï¼‰"""
        if not alpha_ids:
            return
        
        try:
            # åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
            from database.db_manager import FactorDatabaseManager
            db = FactorDatabaseManager(self.config.db_path)
            
            # æ‰¹é‡ç§»é™¤å·²æäº¤çš„Alpha
            removed_count = db.remove_submitable_alphas_batch(alpha_ids)
            
            if removed_count > 0:
                self.logger.info(f"    âœ… æˆåŠŸä»æ•°æ®åº“ç§»é™¤ {removed_count} ä¸ªå·²æäº¤Alpha")
            else:
                self.logger.info(f"    â„¹ï¸ è¿™äº›Alphaä¸åœ¨æ•°æ®åº“ä¸­ï¼Œæ— éœ€ç§»é™¤")
                
        except Exception as e:
            self.logger.error(f"    âŒ æ‰¹é‡ç§»é™¤å·²æäº¤Alphaå¤±è´¥: {e}")
            # å›é€€åˆ°å•ä¸ªç§»é™¤
            self.logger.info(f"    ğŸ”„ å›é€€åˆ°å•ä¸ªç§»é™¤æ¨¡å¼...")
            try:
                from database.db_manager import FactorDatabaseManager
                db = FactorDatabaseManager(self.config.db_path)
                
                success_count = 0
                for alpha_id in alpha_ids:
                    try:
                        if db.remove_submitable_alpha(alpha_id):
                            success_count += 1
                    except Exception as e:
                        self.logger.debug(f"      ç§»é™¤Alpha {alpha_id}å¤±è´¥: {e}")
                
                if success_count > 0:
                    self.logger.info(f"    âœ… å•ä¸ªç§»é™¤å®Œæˆï¼ŒæˆåŠŸç§»é™¤ {success_count}/{len(alpha_ids)} ä¸ªAlpha")
                else:
                    self.logger.info(f"    â„¹ï¸ è¿™äº›Alphaä¸åœ¨æ•°æ®åº“ä¸­ï¼Œæ— éœ€ç§»é™¤")
                    
            except Exception as e2:
                self.logger.error(f"    âŒ å•ä¸ªç§»é™¤ä¹Ÿå¤±è´¥: {e2}")
