#!/usr/bin/env python3
"""
ä½œè€…ï¼še.e.
æ—¥æœŸï¼š2025.09.10
åŠŸèƒ½ï¼šå°†ç°æœ‰æ–‡æœ¬æ–‡ä»¶æ•°æ®è¿ç§»åˆ°SQLiteæ•°æ®åº“
"""

import os
import sys
import sqlite3
import pandas as pd
import re
from datetime import datetime
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from config import RECORDS_PATH, ROOT_PATH

class FactorDataMigrator:
    def __init__(self, db_path='database/factors.db'):
        """åˆå§‹åŒ–è¿ç§»å™¨"""
        self.db_path = os.path.join(ROOT_PATH, db_path)
        self.records_path = RECORDS_PATH
        self.conn = None
        
        # ç¡®ä¿æ•°æ®åº“ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        
    def connect_db(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.conn = sqlite3.connect(self.db_path)
            self.conn.execute("PRAGMA foreign_keys = ON")
            print(f"âœ… æˆåŠŸè¿æ¥æ•°æ®åº“: {self.db_path}")
            return True
        except Exception as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False
            
    def create_schema(self):
        """åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„"""
        try:
            # æ£€æŸ¥è¡¨æ˜¯å¦å·²å­˜åœ¨
            cursor = self.conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            existing_tables = {row[0] for row in cursor.fetchall()}
            
            # å®šä¹‰éœ€è¦çš„è¡¨
            required_tables = ['factor_expressions', 'checked_alphas', 'submitable_alphas', 'failed_expressions', 'system_config']
            
            # å¦‚æœæ‰€æœ‰è¡¨éƒ½å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º
            if all(table in existing_tables for table in required_tables):
                print("âœ… æ•°æ®åº“è¡¨ç»“æ„å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
                # æ£€æŸ¥å¹¶æ·»åŠ å¤æŸ¥æ ‡è®°åˆ—
                self._add_recheck_flag_if_missing()
                return True
            
            # è¯»å–å¹¶ä¿®æ”¹ schema.sqlï¼Œæ·»åŠ  IF NOT EXISTS
            schema_path = os.path.join(ROOT_PATH, 'database', 'schema.sql')
            with open(schema_path, 'r', encoding='utf-8') as f:
                schema_sql = f.read()
            
            # æ›¿æ¢ CREATE TABLE ä¸º CREATE TABLE IF NOT EXISTS
            schema_sql = schema_sql.replace('CREATE TABLE ', 'CREATE TABLE IF NOT EXISTS ')
            # æ›¿æ¢ CREATE INDEX ä¸º CREATE INDEX IF NOT EXISTS  
            schema_sql = schema_sql.replace('CREATE INDEX ', 'CREATE INDEX IF NOT EXISTS ')
            # æ›¿æ¢ CREATE VIEW ä¸º CREATE VIEW IF NOT EXISTS
            schema_sql = schema_sql.replace('CREATE VIEW ', 'CREATE VIEW IF NOT EXISTS ')
            
            # å¤„ç† INSERT è¯­å¥ï¼Œä½¿ç”¨ INSERT OR IGNORE
            schema_sql = schema_sql.replace('INSERT INTO system_config', 'INSERT OR IGNORE INTO system_config')
            
            # æ‰§è¡ŒSQLåˆ›å»ºè¡¨
            self.conn.executescript(schema_sql)
            self.conn.commit()
            print("âœ… æ•°æ®åº“è¡¨ç»“æ„åˆ›å»ºæˆåŠŸ")
            
            # æ£€æŸ¥å¹¶æ·»åŠ å¤æŸ¥æ ‡è®°åˆ—
            self._add_recheck_flag_if_missing()
            return True
        except Exception as e:
            print(f"âŒ åˆ›å»ºè¡¨ç»“æ„å¤±è´¥: {e}")
            return False
            
    def _add_recheck_flag_if_missing(self):
        """æ£€æŸ¥å¹¶æ·»åŠ å¤æŸ¥æ ‡è®°åˆ—ï¼ˆå¦‚æœç¼ºå¤±ï¼‰"""
        try:
            # æ£€æŸ¥recheck_flagåˆ—æ˜¯å¦å­˜åœ¨
            cursor = self.conn.cursor()
            cursor.execute("PRAGMA table_info(submitable_alphas)")
            columns = [column[1] for column in cursor.fetchall()]
            
            if 'recheck_flag' not in columns:
                print("ğŸ”„ æ·»åŠ å¤æŸ¥æ ‡è®°åˆ—...")
                
                # æ·»åŠ å¤æŸ¥æ ‡è®°åˆ—
                self.conn.execute("ALTER TABLE submitable_alphas ADD COLUMN recheck_flag BOOLEAN DEFAULT FALSE")
                
                # åˆ›å»ºç´¢å¼•
                self.conn.execute("CREATE INDEX IF NOT EXISTS idx_submitable_recheck_flag ON submitable_alphas(recheck_flag)")
                self.conn.execute("CREATE INDEX IF NOT EXISTS idx_submitable_region_recheck ON submitable_alphas(region, recheck_flag)")
                
                # æ›´æ–°æ•°æ®åº“ç‰ˆæœ¬
                self.conn.execute("""
                    INSERT OR REPLACE INTO system_config (config_key, config_value, description, updated_at)
                    VALUES ('db_version', '1.1', 'æ•°æ®åº“ç‰ˆæœ¬', datetime('now'))
                """)
                
                # è®°å½•è¿ç§»
                self.conn.execute("""
                    INSERT OR REPLACE INTO system_config (config_key, config_value, description)
                    VALUES ('recheck_flag_migration', datetime('now'), 'æ·»åŠ å¤æŸ¥æ ‡è®°åˆ—çš„è¿ç§»æ—¶é—´')
                """)
                
                self.conn.commit()
                print("âœ… å¤æŸ¥æ ‡è®°åˆ—æ·»åŠ æˆåŠŸ")
            else:
                print("âœ… å¤æŸ¥æ ‡è®°åˆ—å·²å­˜åœ¨")
                
        except Exception as e:
            print(f"âŒ æ·»åŠ å¤æŸ¥æ ‡è®°åˆ—å¤±è´¥: {e}")
            
    def parse_filename_info(self, filename):
        """è§£ææ–‡ä»¶åè·å–æ•°æ®é›†å’Œåœ°åŒºä¿¡æ¯"""
        # ç¤ºä¾‹: analyst4_usa_1step_simulated_alpha_expression.txt
        # ç¤ºä¾‹: fundamental2_usa_1step_simulated_alpha_expression.txt
        patterns = [
            r'(\w+)_(\w+)_(\d+)step_simulated_alpha_expression\.txt',
            r'(\w+)_(\w+)_(\d+)step_checked_alpha_id\.txt'
        ]
        
        for pattern in patterns:
            match = re.match(pattern, filename)
            if match:
                dataset_id = match.group(1)
                region = match.group(2).upper()
                step = int(match.group(3))
                return dataset_id, region, step
        
        return None, None, None
        
    def migrate_factor_expressions(self):
        """è¿ç§»å› å­è¡¨è¾¾å¼æ•°æ®"""
        print("\nğŸ”„ å¼€å§‹è¿ç§»å› å­è¡¨è¾¾å¼æ•°æ®...")
        total_migrated = 0
        
        # æŸ¥æ‰¾æ‰€æœ‰è¡¨è¾¾å¼æ–‡ä»¶
        expression_files = []
        for file in os.listdir(self.records_path):
            if file.endswith('_simulated_alpha_expression.txt'):
                expression_files.append(file)
        
        for filename in expression_files:
            dataset_id, region, step = self.parse_filename_info(filename)
            if not all([dataset_id, region, step]):
                print(f"âš ï¸  è·³è¿‡æ— æ³•è§£æçš„æ–‡ä»¶: {filename}")
                continue
                
            file_path = os.path.join(self.records_path, filename)
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    expressions = [line.strip() for line in f if line.strip()]
                
                # æ‰¹é‡æ’å…¥æ•°æ®åº“
                for expression in expressions:
                    try:
                        self.conn.execute("""
                            INSERT OR IGNORE INTO factor_expressions 
                            (expression, dataset_id, region, step) 
                            VALUES (?, ?, ?, ?)
                        """, (expression, dataset_id, region, step))
                    except Exception as e:
                        print(f"âš ï¸  æ’å…¥è¡¨è¾¾å¼å¤±è´¥: {expression[:50]}... - {e}")
                
                self.conn.commit()
                count = len(expressions)
                total_migrated += count
                print(f"âœ… {filename}: è¿ç§» {count} æ¡è¡¨è¾¾å¼")
                
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ {filename} å¤±è´¥: {e}")
        
        print(f"ğŸ“Š å› å­è¡¨è¾¾å¼è¿ç§»å®Œæˆï¼Œæ€»è®¡: {total_migrated} æ¡")
        
    def migrate_checked_alphas(self):
        """è¿ç§»å·²æ£€æŸ¥å› å­æ•°æ®"""
        print("\nğŸ”„ å¼€å§‹è¿ç§»å·²æ£€æŸ¥å› å­æ•°æ®...")
        total_migrated = 0
        
        # æŸ¥æ‰¾æ‰€æœ‰å·²æ£€æŸ¥æ–‡ä»¶
        checked_files = []
        for file in os.listdir(self.records_path):
            if file.endswith('_checked_alpha_id.txt'):
                checked_files.append(file)
        
        for filename in checked_files:
            dataset_id, region, step = self.parse_filename_info(filename)
            if not all([dataset_id, region, step]):
                print(f"âš ï¸  è·³è¿‡æ— æ³•è§£æçš„æ–‡ä»¶: {filename}")
                continue
                
            file_path = os.path.join(self.records_path, filename)
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    alpha_ids = [line.strip() for line in f if line.strip()]
                
                # æ‰¹é‡æ’å…¥æ•°æ®åº“
                for alpha_id in alpha_ids:
                    try:
                        self.conn.execute("""
                            INSERT OR IGNORE INTO checked_alphas 
                            (alpha_id, dataset_id, region, step) 
                            VALUES (?, ?, ?, ?)
                        """, (alpha_id, dataset_id, region, step))
                    except Exception as e:
                        print(f"âš ï¸  æ’å…¥Alpha IDå¤±è´¥: {alpha_id} - {e}")
                
                self.conn.commit()
                count = len(alpha_ids)
                total_migrated += count
                print(f"âœ… {filename}: è¿ç§» {count} ä¸ªAlpha ID")
                
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ {filename} å¤±è´¥: {e}")
        
        print(f"ğŸ“Š å·²æ£€æŸ¥å› å­è¿ç§»å®Œæˆï¼Œæ€»è®¡: {total_migrated} æ¡")
        
    def migrate_submitable_alphas(self):
        """è¿ç§»å¯æäº¤å› å­æ•°æ®"""
        print("\nğŸ”„ å¼€å§‹è¿ç§»å¯æäº¤å› å­æ•°æ®...")
        
        csv_path = os.path.join(self.records_path, 'submitable_alpha.csv')
        if not os.path.exists(csv_path):
            print("âš ï¸  submitable_alpha.csv æ–‡ä»¶ä¸å­˜åœ¨")
            return
            
        try:
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(csv_path)
            
            if df.empty:
                print("âš ï¸  submitable_alpha.csv æ–‡ä»¶ä¸ºç©º")
                return
            
            # è½¬æ¢åˆ—åï¼šé©¼å³°è½¬ä¸‹åˆ’çº¿
            column_mapping = {}
            for col in df.columns:
                # å°†é©¼å³°å‘½åè½¬æ¢ä¸ºä¸‹åˆ’çº¿å‘½å
                snake_case = re.sub('([a-z0-9])([A-Z])', r'\1_\2', col).lower()
                column_mapping[col] = snake_case
            
            df = df.rename(columns=column_mapping)
            
            # é€è¡Œæ’å…¥æ•°æ®åº“ï¼Œé¿å…é‡å¤
            for _, row in df.iterrows():
                try:
                    # ä½¿ç”¨INSERT OR IGNOREé¿å…é‡å¤æ’å…¥
                    columns = ', '.join(row.index)
                    placeholders = ', '.join(['?' for _ in range(len(row))])
                    query = f"INSERT OR IGNORE INTO submitable_alphas ({columns}) VALUES ({placeholders})"
                    self.conn.execute(query, tuple(row.values))
                except Exception as e:
                    print(f"âš ï¸  æ’å…¥å¯æäº¤å› å­å¤±è´¥: {row.get('id', 'Unknown')} - {e}")
            
            self.conn.commit()
            
            count = len(df)
            print(f"âœ… å¯æäº¤å› å­è¿ç§»å®Œæˆ: {count} æ¡")
            
        except Exception as e:
            print(f"âŒ è¿ç§»å¯æäº¤å› å­å¤±è´¥: {e}")
            
    # notified_alphas.txt ä¸éœ€è¦è¿ç§»åˆ°æ•°æ®åº“
    # è¿™ç±»é€šçŸ¥æ—¥å¿—æ–‡ä»¶ä¿æŒæ–‡ä»¶å­˜å‚¨æ–¹å¼å³å¯
            
    def migrate_config(self):
        """è¿ç§»é…ç½®æ•°æ®"""
        print("\nğŸ”„ å¼€å§‹è¿ç§»é…ç½®æ•°æ®...")
        
        # è¿ç§»å¼€å§‹æ—¥æœŸ
        start_date_path = os.path.join(self.records_path, 'start_date.txt')
        if os.path.exists(start_date_path):
            try:
                with open(start_date_path, 'r', encoding='utf-8') as f:
                    start_date = f.read().strip()
                
                self.conn.execute("""
                    INSERT OR REPLACE INTO system_config 
                    (config_key, config_value, description) 
                    VALUES (?, ?, ?)
                """, ('start_date', start_date, 'å› å­æŒ–æ˜å¼€å§‹æ—¥æœŸ'))
                
                self.conn.commit()
                print(f"âœ… å¼€å§‹æ—¥æœŸé…ç½®è¿ç§»å®Œæˆ: {start_date}")
                
            except Exception as e:
                print(f"âŒ è¿ç§»å¼€å§‹æ—¥æœŸé…ç½®å¤±è´¥: {e}")
        
    def verify_migration(self):
        """éªŒè¯è¿ç§»ç»“æœ"""
        print("\nğŸ“Š éªŒè¯è¿ç§»ç»“æœ...")
        
        try:
            # æŸ¥è¯¢å„è¡¨æ•°æ®é‡
            tables = ['factor_expressions', 'checked_alphas', 'submitable_alphas', 'system_config']
            
            for table in tables:
                cursor = self.conn.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                print(f"  {table}: {count} æ¡è®°å½•")
            
            # æ˜¾ç¤ºç³»ç»Ÿæ¦‚è§ˆ
            print("\nğŸ“ˆ æ•°æ®åˆ†å¸ƒç»Ÿè®¡:")
            cursor = self.conn.execute("SELECT * FROM system_overview")
            for row in cursor.fetchall():
                print(f"  {row[0]}: {row[1]} æ¡è®°å½•ï¼Œæœ€æ–°æ›´æ–°: {row[2]}")
                
        except Exception as e:
            print(f"âŒ éªŒè¯è¿ç§»ç»“æœå¤±è´¥: {e}")
            
    def run_migration(self):
        """æ‰§è¡Œå®Œæ•´è¿ç§»æµç¨‹"""
        print("ğŸš€ å¼€å§‹æ•°æ®è¿ç§»...")
        
        if not self.connect_db():
            return False
            
        try:
            # 1. åˆ›å»ºè¡¨ç»“æ„
            if not self.create_schema():
                return False
            
            # 2. è¿ç§»å„ç±»æ•°æ®
            self.migrate_factor_expressions()
            self.migrate_checked_alphas()
            self.migrate_submitable_alphas()
            self.migrate_config()
            
            print("ğŸ“ æ³¨æ„: notified_alphas.txt ç­‰é€šçŸ¥æ—¥å¿—æ–‡ä»¶ä¿æŒåŸæœ‰æ–‡ä»¶å­˜å‚¨æ–¹å¼")
            
            # 3. éªŒè¯ç»“æœ
            self.verify_migration()
            
            print("\nâœ… æ•°æ®è¿ç§»å®Œæˆï¼")
            print(f"ğŸ“ æ•°æ®åº“ä½ç½®: {self.db_path}")
            
            return True
            
        except Exception as e:
            print(f"âŒ è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
            
        finally:
            if self.conn:
                self.conn.close()

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("  WorldQuant å› å­ç³»ç»Ÿæ•°æ®è¿ç§»å·¥å…·")
    print("  ä»æ–‡æœ¬æ–‡ä»¶è¿ç§»åˆ°SQLiteæ•°æ®åº“")
    print("=" * 60)
    
    migrator = FactorDataMigrator()
    success = migrator.run_migration()
    
    if success:
        print("\nğŸ‰ è¿ç§»æˆåŠŸï¼ç°åœ¨å¯ä»¥ä½¿ç”¨æ•°æ®åº“è¿›è¡Œå› å­ç®¡ç†äº†ã€‚")
    else:
        print("\nğŸ’¥ è¿ç§»å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶é‡è¯•ã€‚")
        sys.exit(1)

if __name__ == "__main__":
    main()