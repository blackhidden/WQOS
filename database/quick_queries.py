#!/usr/bin/env python3
"""
ä½œè€…ï¼še.e.
æ—¥æœŸï¼š2025.09.10
åŠŸèƒ½ï¼šå¿«é€ŸæŸ¥è¯¢è„šæœ¬ï¼Œæä¾›å¸¸ç”¨çš„æ•°æ®åº“æŸ¥è¯¢å‘½ä»¤
"""

import os
import sys
import argparse

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from db_manager import FactorDatabaseManager

def show_stats():
    """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
    print("ğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯")
    print("="*40)
    
    db = FactorDatabaseManager()
    
    stats = db.get_system_stats()
    
    print(f"ğŸ“ˆ æ€»æ•°ç»Ÿè®¡:")
    print(f"  - å› å­è¡¨è¾¾å¼: {stats.get('total_expressions', 0):,} æ¡")
    print(f"  - å·²æ£€æŸ¥å› å­: {stats.get('total_checked', 0):,} ä¸ª")
    print(f"  - å¯æäº¤å› å­: {stats.get('total_submitable', 0):,} ä¸ª")
    
    print(f"\nğŸ“‹ å„æ•°æ®é›†åˆ†å¸ƒ:")
    breakdown = stats.get('expression_breakdown', [])
    for dataset_id, region, step, count in breakdown:
        print(f"  - {dataset_id}_{region}_{step}step: {count:,} æ¡")

def show_latest(limit=10):
    """æ˜¾ç¤ºæœ€æ–°çš„è®°å½•"""
    print(f"ğŸ•’ æœ€æ–° {limit} æ¡è®°å½•")
    print("="*40)
    
    db = FactorDatabaseManager()
    
    try:
        with db.get_connection() as conn:
            # æœ€æ–°çš„å› å­è¡¨è¾¾å¼
            print("ğŸ“ æœ€æ–°å› å­è¡¨è¾¾å¼:")
            cursor = conn.execute("""
                SELECT expression, dataset_id, region, step, created_at
                FROM factor_expressions 
                ORDER BY created_at DESC 
                LIMIT ?
            """, (limit,))
            
            for i, (expr, dataset_id, region, step, created) in enumerate(cursor.fetchall(), 1):
                print(f"  {i:2d}. {expr[:50]}{'...' if len(expr) > 50 else ''}")
                print(f"      [{dataset_id}_{region}_{step}step] {created}")
            
            # æœ€æ–°çš„æ£€æŸ¥è®°å½•
            print(f"\nâœ… æœ€æ–°å·²æ£€æŸ¥å› å­:")
            cursor = conn.execute("""
                SELECT alpha_id, dataset_id, region, step, checked_at
                FROM checked_alphas 
                ORDER BY checked_at DESC 
                LIMIT ?
            """, (limit,))
            
            for i, (alpha_id, dataset_id, region, step, checked) in enumerate(cursor.fetchall(), 1):
                print(f"  {i:2d}. {alpha_id} [{dataset_id}_{region}_{step}step] {checked}")
                
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")

def search_expressions(keyword, limit=10):
    """æœç´¢å› å­è¡¨è¾¾å¼"""
    print(f"ğŸ” æœç´¢åŒ…å« '{keyword}' çš„å› å­è¡¨è¾¾å¼")
    print("="*40)
    
    db = FactorDatabaseManager()
    
    try:
        with db.get_connection() as conn:
            cursor = conn.execute("""
                SELECT expression, dataset_id, region, step, created_at
                FROM factor_expressions 
                WHERE expression LIKE ?
                ORDER BY created_at DESC 
                LIMIT ?
            """, (f"%{keyword}%", limit))
            
            results = cursor.fetchall()
            if not results:
                print(f"âŒ æœªæ‰¾åˆ°åŒ…å« '{keyword}' çš„è¡¨è¾¾å¼")
                return
            
            print(f"ğŸ“‹ æ‰¾åˆ° {len(results)} æ¡ç»“æœ:")
            for i, (expr, dataset_id, region, step, created) in enumerate(results, 1):
                print(f"  {i:2d}. {expr}")
                print(f"      [{dataset_id}_{region}_{step}step] {created}")
                
    except Exception as e:
        print(f"âŒ æœç´¢å¤±è´¥: {e}")

def show_dataset_info(dataset_id, region="", step=None):
    """æ˜¾ç¤ºæŒ‡å®šæ•°æ®é›†ä¿¡æ¯"""
    filter_desc = f"{dataset_id}"
    if region:
        filter_desc += f"_{region}"
    if step is not None:
        filter_desc += f"_{step}step"
    
    print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯: {filter_desc}")
    print("="*40)
    
    db = FactorDatabaseManager()
    
    try:
        with db.get_connection() as conn:
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            conditions = ["dataset_id = ?"]
            params = [dataset_id]
            
            if region:
                conditions.append("region = ?")
                params.append(region)
            
            if step is not None:
                conditions.append("step = ?")
                params.append(step)
            
            where_clause = " AND ".join(conditions)
            
            # è¡¨è¾¾å¼ç»Ÿè®¡
            cursor = conn.execute(f"""
                SELECT COUNT(*), MIN(created_at), MAX(created_at)
                FROM factor_expressions 
                WHERE {where_clause}
            """, params)
            
            expr_count, first_created, last_created = cursor.fetchone()
            print(f"ğŸ“ å› å­è¡¨è¾¾å¼: {expr_count:,} æ¡")
            if first_created:
                print(f"   é¦–æ¬¡åˆ›å»º: {first_created}")
                print(f"   æœ€è¿‘åˆ›å»º: {last_created}")
            
            # æ£€æŸ¥ç»Ÿè®¡
            cursor = conn.execute(f"""
                SELECT COUNT(*), MIN(checked_at), MAX(checked_at)
                FROM checked_alphas 
                WHERE {where_clause}
            """, params)
            
            checked_count, first_checked, last_checked = cursor.fetchone()
            print(f"\nâœ… å·²æ£€æŸ¥å› å­: {checked_count:,} ä¸ª")
            if first_checked:
                print(f"   é¦–æ¬¡æ£€æŸ¥: {first_checked}")
                print(f"   æœ€è¿‘æ£€æŸ¥: {last_checked}")
            
            # æ£€æŸ¥ç‡
            if expr_count > 0:
                check_rate = checked_count * 100.0 / expr_count
                print(f"\nğŸ“Š æ£€æŸ¥ç‡: {check_rate:.1f}%")
            
            # å¸¸ç”¨æ“ä½œç¬¦ç»Ÿè®¡
            print(f"\nğŸ”§ å¸¸ç”¨æ“ä½œç¬¦ç»Ÿè®¡:")
            operators = ['ts_rank', 'ts_mean', 'ts_sum', 'rank', 'winsorize']
            
            for op in operators:
                cursor = conn.execute(f"""
                    SELECT COUNT(*) FROM factor_expressions 
                    WHERE {where_clause} AND expression LIKE ?
                """, params + [f"%{op}%"])
                
                op_count = cursor.fetchone()[0]
                if op_count > 0:
                    percentage = op_count * 100.0 / expr_count if expr_count > 0 else 0
                    print(f"   {op}: {op_count:,} æ¬¡ ({percentage:.1f}%)")
                
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")

def show_daily_stats(limit=30, timezone_offset=None):
    """æ˜¾ç¤ºæ¯æ—¥å› å­è¡¨è¾¾å¼æ’å…¥ç»Ÿè®¡"""
    
    # æ—¶åŒºè¯´æ˜
    tz_info = ""
    if timezone_offset is not None:
        if timezone_offset > 0:
            tz_info = f" (UTC+{timezone_offset})"
        elif timezone_offset < 0:
            tz_info = f" (UTC{timezone_offset})"
        else:
            tz_info = " (UTC)"
    else:
        tz_info = " (æœ¬åœ°æ—¶åŒº)"
    
    print(f"ğŸ“… æ¯æ—¥å› å­è¡¨è¾¾å¼æ’å…¥ç»Ÿè®¡ (æœ€è¿‘ {limit} å¤©){tz_info}")
    print("="*60)
    
    db = FactorDatabaseManager()
    
    try:
        with db.get_connection() as conn:
            # æ„å»ºæ—¶åŒºè½¬æ¢çš„SQL
            if timezone_offset is not None:
                # ä½¿ç”¨æŒ‡å®šæ—¶åŒºåç§»
                date_expr = f"DATE(created_at, '{timezone_offset:+d} hours')"
            else:
                # ä½¿ç”¨æœ¬åœ°æ—¶åŒºï¼ˆç³»ç»Ÿé»˜è®¤ï¼‰
                date_expr = "DATE(created_at, 'localtime')"
            
            cursor = conn.execute(f"""
                SELECT 
                    {date_expr} as date,
                    COUNT(*) as total_expressions,
                    COUNT(DISTINCT dataset_id) as unique_datasets,
                    COUNT(DISTINCT region) as unique_regions
                FROM factor_expressions 
                GROUP BY {date_expr}
                ORDER BY date DESC 
                LIMIT ?
            """, (limit,))
            
            results = cursor.fetchall()
            if not results:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•å› å­è¡¨è¾¾å¼è®°å½•")
                return
            
            print(f"{'æ—¥æœŸ':<12} {'è¡¨è¾¾å¼æ•°é‡':<10} {'æ•°æ®é›†æ•°':<8} {'åœ°åŒºæ•°':<6}")
            print("-" * 60)
            
            total_expressions = 0
            for date, expr_count, dataset_count, region_count in results:
                total_expressions += expr_count
                print(f"{date:<12} {expr_count:<10,} {dataset_count:<8} {region_count:<6}")
            
            print("-" * 60)
            print(f"{'æ€»è®¡':<12} {total_expressions:<10,}")
            
            # æ˜¾ç¤ºè¶‹åŠ¿ä¿¡æ¯
            if len(results) >= 2:
                recent_avg = sum(row[1] for row in results[:7]) / min(7, len(results))
                print(f"\nğŸ“Š æœ€è¿‘å¹³å‡æ¯æ—¥: {recent_avg:.1f} ä¸ªè¡¨è¾¾å¼")
            
            # æ—¶åŒºè¯´æ˜
            if timezone_offset == -4:
                print(f"\nğŸŒ ä½¿ç”¨ç¾å›½ä¸œéƒ¨æ—¶é—´ (UTC-4)ï¼Œä¸WorldQuantå¹³å°ä¸€è‡´")
            elif timezone_offset is None:
                print(f"\nğŸŒ ä½¿ç”¨æœ¬åœ°ç³»ç»Ÿæ—¶åŒºï¼Œå¯èƒ½ä¸å¹³å°æ—¶åŒºä¸åŒ")
                print(f"ğŸ’¡ å»ºè®®ä½¿ç”¨: --et (ç¾å›½ä¸œéƒ¨æ—¶é—´) ä¸å¹³å°ä¿æŒä¸€è‡´")
                
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")

def show_submitable():
    """æ˜¾ç¤ºå¯æäº¤å› å­"""
    print("ğŸš€ å¯æäº¤å› å­åˆ—è¡¨")
    print("="*40)
    
    db = FactorDatabaseManager()
    df = db.get_submitable_alphas()
    
    if df.empty:
        print("âŒ å½“å‰æ²¡æœ‰å¯æäº¤çš„å› å­")
        return
    
    print(f"ğŸ“‹ å…±æœ‰ {len(df)} ä¸ªå¯æäº¤å› å­:")
    
    # æ˜¾ç¤ºå…³é”®åˆ—
    key_columns = ['alpha_id', 'sharpe', 'fitness', 'turnover', 'region', 'universe']
    available_columns = [col for col in key_columns if col in df.columns]
    
    if available_columns:
        print(df[available_columns].to_string(index=False))
    else:
        print(df.to_string(index=False))

def show_daily_submit_limit():
    """æ˜¾ç¤ºæ¯æ—¥æäº¤é™é¢çŠ¶æ€"""
    print("ğŸ“… æ¯æ—¥æäº¤é™é¢çŠ¶æ€")
    print("="*50)
    
    db = FactorDatabaseManager()
    
    try:
        # å¯¼å…¥é…ç½®å’Œæ—¶åŒºå‡½æ•°
        sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))
        from machine_lib_ee import load_digging_config, get_current_date_with_timezone
        
        # åŠ è½½é…ç½®
        config = load_digging_config()
        daily_limit = config.get('daily_submit_limit', 0)
        limit_timezone = config.get('daily_limit_timezone', 'UTC')
        limit_behavior = config.get('daily_limit_behavior', 'wait')
        
        print(f"âš™ï¸  é…ç½®ä¿¡æ¯:")
        print(f"  - æ¯æ—¥é™é¢: {daily_limit} ä¸ª/å¤©" + (" (æ— é™åˆ¶)" if daily_limit == 0 else ""))
        print(f"  - æ—¶åŒºè®¾ç½®: {limit_timezone}")
        print(f"  - é™é¢è¡Œä¸º: {limit_behavior}")
        
        if daily_limit > 0:
            # è·å–å½“å‰æ—¥æœŸ
            current_date = get_current_date_with_timezone(limit_timezone)
            
            # è·å–ä»Šæ—¥ç»Ÿè®¡
            daily_stats = db.get_daily_submit_stats(current_date, limit_timezone)
            today_successful = daily_stats['successful_submits']
            today_attempts = daily_stats['total_attempts']
            remaining_quota = daily_limit - today_successful
            
            print(f"\nğŸ“Š ä»Šæ—¥çŠ¶æ€ [{current_date}]:")
            print(f"  - âœ… æˆåŠŸæäº¤: {today_successful} ä¸ª")
            print(f"  - ğŸ¯ æ€»å°è¯•æ•°: {today_attempts} ä¸ª")
            print(f"  - ğŸ“ˆ æˆåŠŸç‡: {today_successful/today_attempts*100:.1f}%" if today_attempts > 0 else "  - ğŸ“ˆ æˆåŠŸç‡: N/A")
            print(f"  - ğŸ”„ å‰©ä½™é…é¢: {remaining_quota} ä¸ª")
            
            # çŠ¶æ€æŒ‡ç¤º
            if remaining_quota <= 0:
                print(f"  - âš ï¸  çŠ¶æ€: é™é¢å·²ç”¨å®Œ")
            elif remaining_quota <= daily_limit * 0.2:  # å°‘äº20%
                print(f"  - ğŸ”¸ çŠ¶æ€: é…é¢ä¸è¶³")
            else:
                print(f"  - âœ… çŠ¶æ€: é…é¢å……è¶³")
        
        # è·å–æœ€è¿‘å‡ å¤©çš„ç»Ÿè®¡
        print(f"\nğŸ“ˆ æœ€è¿‘7å¤©ç»Ÿè®¡:")
        recent_stats = db.get_recent_daily_stats(7)
        if recent_stats:
            print(f"{'æ—¥æœŸ':>12} {'æˆåŠŸ':>6} {'å°è¯•':>6} {'æˆåŠŸç‡':>8} {'å‰©ä½™é…é¢':>8}")
            print("-" * 50)
            for stat in recent_stats:
                date = stat['date']
                successful = stat['successful_submits']
                attempts = stat['total_attempts']
                success_rate = stat['success_rate']
                remaining = daily_limit - successful if daily_limit > 0 else "æ— é™åˆ¶"
                
                print(f"{date:>12} {successful:>6} {attempts:>6} {success_rate:>7}% {str(remaining):>8}")
        else:
            print("  æš‚æ— å†å²æ•°æ®")
    
    except Exception as e:
        print(f"âŒ è·å–æ¯æ—¥é™é¢çŠ¶æ€å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='WorldQuant å› å­æ•°æ®åº“å¿«é€ŸæŸ¥è¯¢å·¥å…·')
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # statså‘½ä»¤
    stats_parser = subparsers.add_parser('stats', help='æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯')
    
    # latestå‘½ä»¤
    latest_parser = subparsers.add_parser('latest', help='æ˜¾ç¤ºæœ€æ–°è®°å½•')
    latest_parser.add_argument('--limit', type=int, default=10, help='æ˜¾ç¤ºæ•°é‡ (é»˜è®¤10)')
    
    # searchå‘½ä»¤
    search_parser = subparsers.add_parser('search', help='æœç´¢å› å­è¡¨è¾¾å¼')
    search_parser.add_argument('keyword', help='æœç´¢å…³é”®è¯')
    search_parser.add_argument('--limit', type=int, default=10, help='æ˜¾ç¤ºæ•°é‡ (é»˜è®¤10)')
    
    # datasetå‘½ä»¤
    dataset_parser = subparsers.add_parser('dataset', help='æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯')
    dataset_parser.add_argument('dataset_id', help='æ•°æ®é›†ID (å¦‚: analyst4)')
    dataset_parser.add_argument('--region', help='åœ°åŒº (å¦‚: USA)')
    dataset_parser.add_argument('--step', type=int, choices=[1, 2], help='æ­¥éª¤ (1æˆ–2)')
    
    # submitableå‘½ä»¤
    submitable_parser = subparsers.add_parser('submitable', help='æ˜¾ç¤ºå¯æäº¤å› å­')
    
    # dailyå‘½ä»¤
    daily_parser = subparsers.add_parser('daily', help='æ˜¾ç¤ºæ¯æ—¥å› å­è¡¨è¾¾å¼æ’å…¥ç»Ÿè®¡')
    daily_parser.add_argument('--limit', type=int, default=30, help='æ˜¾ç¤ºå¤©æ•° (é»˜è®¤30å¤©)')
    daily_parser.add_argument('--et', action='store_true', help='ä½¿ç”¨ç¾å›½ä¸œéƒ¨æ—¶é—´ (UTC-4)ï¼Œä¸å¹³å°ä¸€è‡´')
    daily_parser.add_argument('--utc', action='store_true', help='ä½¿ç”¨UTCæ—¶é—´')
    daily_parser.add_argument('--tz', type=int, help='æŒ‡å®šæ—¶åŒºåç§» (å°æ—¶)ï¼Œå¦‚ +8 æˆ– -4')
    
    # daily-limitå‘½ä»¤
    daily_limit_parser = subparsers.add_parser('daily-limit', help='æ˜¾ç¤ºæ¯æ—¥æäº¤é™é¢çŠ¶æ€')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    try:
        if args.command == 'stats':
            show_stats()
        elif args.command == 'latest':
            show_latest(args.limit)
        elif args.command == 'search':
            search_expressions(args.keyword, args.limit)
        elif args.command == 'dataset':
            show_dataset_info(args.dataset_id, args.region or "", args.step)
        elif args.command == 'submitable':
            show_submitable()
        elif args.command == 'daily':
            # è§£ææ—¶åŒºå‚æ•°
            timezone_offset = None
            if args.et:
                timezone_offset = -4  # ç¾å›½ä¸œéƒ¨æ—¶é—´
            elif args.utc:
                timezone_offset = 0   # UTCæ—¶é—´
            elif args.tz is not None:
                timezone_offset = args.tz  # ç”¨æˆ·æŒ‡å®šçš„æ—¶åŒº
            
            show_daily_stats(args.limit, timezone_offset)
        elif args.command == 'daily-limit':
            show_daily_submit_limit()
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()