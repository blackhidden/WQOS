"""
æ•°æ®é›†åˆ†åº“ç®¡ç†å™¨
ä½œè€…ï¼še.e.
æ—¥æœŸï¼š2025.09.05

åŠŸèƒ½ï¼š
- ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ›å»ºç‹¬ç«‹çš„SQLiteæ•°æ®åº“
- åªå­˜å‚¨factor_expressionsè¡¨
- å…¶ä»–è¡¨ä»ä½¿ç”¨ä¸»æ•°æ®åº“
- æä¾›ç»Ÿä¸€çš„æŸ¥è¯¢æ¥å£
"""

import os
import sqlite3
import threading
from typing import List, Dict, Any, Optional
from contextlib import contextmanager
from database.db_manager import FactorDatabaseManager


class PartitionedFactorManager:
    """æ•°æ®é›†åˆ†åº“å› å­ç®¡ç†å™¨"""
    
    def __init__(self, main_db_path: str, partitions_dir: str = None):
        """
        åˆå§‹åŒ–åˆ†åº“ç®¡ç†å™¨
        
        Args:
            main_db_path: ä¸»æ•°æ®åº“è·¯å¾„
            partitions_dir: åˆ†åº“å­˜å‚¨ç›®å½•ï¼Œé»˜è®¤ä¸ºä¸»æ•°æ®åº“åŒç›®å½•ä¸‹çš„partitionsæ–‡ä»¶å¤¹
        """
        self.main_db_path = main_db_path
        
        # è®¾ç½®åˆ†åº“ç›®å½•
        if partitions_dir is None:
            db_dir = os.path.dirname(main_db_path)
            self.partitions_dir = os.path.join(db_dir, 'partitions')
        else:
            self.partitions_dir = partitions_dir
            
        # ç¡®ä¿åˆ†åº“ç›®å½•å­˜åœ¨
        os.makedirs(self.partitions_dir, exist_ok=True)
        
        # ä¸»æ•°æ®åº“ç®¡ç†å™¨ï¼ˆç”¨äºå…¶ä»–è¡¨ï¼‰
        self.main_db = FactorDatabaseManager(main_db_path)
        
        # åˆ†åº“è¿æ¥æ± 
        self._partition_connections = {}
        self._connection_locks = {}
        self._global_lock = threading.Lock()
        
    def _get_partition_db_path(self, dataset_id: str) -> str:
        """è·å–æ•°æ®é›†åˆ†åº“è·¯å¾„"""
        return os.path.join(self.partitions_dir, f'dataset_{dataset_id}.db')
    
    def _ensure_partition_db(self, dataset_id: str) -> str:
        """ç¡®ä¿æ•°æ®é›†åˆ†åº“å­˜åœ¨å¹¶åˆå§‹åŒ–"""
        db_path = self._get_partition_db_path(dataset_id)
        
        if not os.path.exists(db_path):
            # åˆ›å»ºæ–°çš„åˆ†åº“
            conn = sqlite3.connect(db_path)
            conn.execute('''
                CREATE TABLE factor_expressions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    expression TEXT NOT NULL UNIQUE,
                    dataset_id VARCHAR(50) NOT NULL,
                    region VARCHAR(10) NOT NULL,
                    step INTEGER NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    
                    UNIQUE(expression, dataset_id, region, step)
                )
            ''')
            
            # åˆ›å»ºä¼˜åŒ–ç´¢å¼•
            conn.execute('''
                CREATE INDEX idx_expressions_region_step 
                ON factor_expressions(region, step)
            ''')
            conn.execute('''
                CREATE INDEX idx_expressions_created 
                ON factor_expressions(created_at)
            ''')
            conn.execute('''
                CREATE INDEX idx_expressions_covering 
                ON factor_expressions(region, step, expression)
            ''')
            
            conn.commit()
            conn.close()
            print(f"âœ… åˆ›å»ºæ•°æ®é›†åˆ†åº“: {db_path}")
        
        return db_path
    
    @contextmanager
    def _get_partition_connection(self, dataset_id: str):
        """è·å–æ•°æ®é›†åˆ†åº“è¿æ¥ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self._global_lock:
            if dataset_id not in self._connection_locks:
                self._connection_locks[dataset_id] = threading.Lock()
        
        with self._connection_locks[dataset_id]:
            db_path = self._ensure_partition_db(dataset_id)
            
            if dataset_id not in self._partition_connections:
                self._partition_connections[dataset_id] = sqlite3.connect(
                    db_path, check_same_thread=False
                )
                self._partition_connections[dataset_id].row_factory = sqlite3.Row
            
            yield self._partition_connections[dataset_id]
    
    def add_factor_expression(self, expression: str, dataset_id: str, 
                            region: str, step: int) -> bool:
        """æ·»åŠ å•ä¸ªå› å­è¡¨è¾¾å¼åˆ°å¯¹åº”çš„æ•°æ®é›†åˆ†åº“"""
        try:
            with self._get_partition_connection(dataset_id) as conn:
                cursor = conn.execute("""
                    INSERT OR IGNORE INTO factor_expressions 
                    (expression, dataset_id, region, step) 
                    VALUES (?, ?, ?, ?)
                """, (expression, dataset_id, region, step))
                conn.commit()
                return cursor.rowcount > 0
        except Exception as e:
            print(f"âŒ æ·»åŠ å› å­è¡¨è¾¾å¼å¤±è´¥ [{dataset_id}]: {e}")
            return False
    
    def add_factor_expressions_batch(self, expressions: List[str], dataset_id: str, 
                                   region: str, step: int) -> int:
        """æ‰¹é‡æ·»åŠ å› å­è¡¨è¾¾å¼åˆ°å¯¹åº”çš„æ•°æ®é›†åˆ†åº“"""
        try:
            with self._get_partition_connection(dataset_id) as conn:
                data = [(expr, dataset_id, region, step) for expr in expressions]
                cursor = conn.executemany("""
                    INSERT OR IGNORE INTO factor_expressions 
                    (expression, dataset_id, region, step) 
                    VALUES (?, ?, ?, ?)
                """, data)
                conn.commit()
                return cursor.rowcount
        except Exception as e:
            print(f"âŒ æ‰¹é‡æ·»åŠ å› å­è¡¨è¾¾å¼å¤±è´¥ [{dataset_id}]: {e}")
            return 0
    
    def get_factor_expressions(self, dataset_id: str, region: str, step: int) -> List[str]:
        """ä»å¯¹åº”çš„æ•°æ®é›†åˆ†åº“è·å–å› å­è¡¨è¾¾å¼åˆ—è¡¨"""
        try:
            with self._get_partition_connection(dataset_id) as conn:
                cursor = conn.execute("""
                    SELECT expression FROM factor_expressions 
                    WHERE dataset_id = ? AND region = ? AND step = ?
                    ORDER BY created_at
                """, (dataset_id, region, step))
                return [row[0] for row in cursor.fetchall()]
        except Exception as e:
            print(f"âŒ è·å–å› å­è¡¨è¾¾å¼å¤±è´¥ [{dataset_id}]: {e}")
            return []
    
    def is_expression_exists(self, expression: str, dataset_id: str, 
                           region: str, step: int) -> bool:
        """æ£€æŸ¥è¡¨è¾¾å¼æ˜¯å¦å·²å­˜åœ¨äºå¯¹åº”çš„æ•°æ®é›†åˆ†åº“"""
        try:
            with self._get_partition_connection(dataset_id) as conn:
                cursor = conn.execute("""
                    SELECT 1 FROM factor_expressions 
                    WHERE expression = ? AND dataset_id = ? AND region = ? AND step = ?
                    LIMIT 1
                """, (expression, dataset_id, region, step))
                return cursor.fetchone() is not None
        except Exception as e:
            print(f"âŒ æ£€æŸ¥è¡¨è¾¾å¼å­˜åœ¨æ€§å¤±è´¥ [{dataset_id}]: {e}")
            return False
    
    def get_expression_count(self, dataset_id: str, region: str = None, step: int = None) -> int:
        """è·å–æŒ‡å®šæ•°æ®é›†çš„è¡¨è¾¾å¼æ•°é‡"""
        try:
            with self._get_partition_connection(dataset_id) as conn:
                if region and step:
                    cursor = conn.execute("""
                        SELECT COUNT(*) FROM factor_expressions 
                        WHERE dataset_id = ? AND region = ? AND step = ?
                    """, (dataset_id, region, step))
                else:
                    cursor = conn.execute("""
                        SELECT COUNT(*) FROM factor_expressions 
                        WHERE dataset_id = ?
                    """, (dataset_id,))
                return cursor.fetchone()[0]
        except Exception as e:
            print(f"âŒ è·å–è¡¨è¾¾å¼æ•°é‡å¤±è´¥ [{dataset_id}]: {e}")
            return 0
    
    def get_all_datasets(self) -> List[str]:
        """è·å–æ‰€æœ‰å·²åˆ›å»ºçš„æ•°æ®é›†åˆ†åº“åˆ—è¡¨"""
        datasets = []
        if os.path.exists(self.partitions_dir):
            for filename in os.listdir(self.partitions_dir):
                if filename.startswith('dataset_') and filename.endswith('.db'):
                    dataset_id = filename[8:-3]  # ç§»é™¤ 'dataset_' å‰ç¼€å’Œ '.db' åç¼€
                    datasets.append(dataset_id)
        return sorted(datasets)
    
    def get_partition_stats(self) -> Dict[str, Dict[str, Any]]:
        """è·å–æ‰€æœ‰åˆ†åº“çš„ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        for dataset_id in self.get_all_datasets():
            try:
                with self._get_partition_connection(dataset_id) as conn:
                    # æ€»è®°å½•æ•°
                    cursor = conn.execute("SELECT COUNT(*) FROM factor_expressions")
                    total_count = cursor.fetchone()[0]
                    
                    # æŒ‰åœ°åŒºç»Ÿè®¡
                    cursor = conn.execute("""
                        SELECT region, COUNT(*) as count 
                        FROM factor_expressions 
                        GROUP BY region
                    """)
                    by_region = {row[0]: row[1] for row in cursor.fetchall()}
                    
                    # æŒ‰æ­¥éª¤ç»Ÿè®¡
                    cursor = conn.execute("""
                        SELECT step, COUNT(*) as count 
                        FROM factor_expressions 
                        GROUP BY step
                    """)
                    by_step = {row[0]: row[1] for row in cursor.fetchall()}
                    
                    # æ•°æ®åº“æ–‡ä»¶å¤§å°
                    db_path = self._get_partition_db_path(dataset_id)
                    file_size = os.path.getsize(db_path) if os.path.exists(db_path) else 0
                    
                    stats[dataset_id] = {
                        'total_expressions': total_count,
                        'by_region': by_region,
                        'by_step': by_step,
                        'db_size_mb': round(file_size / 1024 / 1024, 2),
                        'db_path': db_path
                    }
            except Exception as e:
                print(f"âŒ è·å–åˆ†åº“ç»Ÿè®¡å¤±è´¥ [{dataset_id}]: {e}")
                stats[dataset_id] = {'error': str(e)}
        
        return stats
    
    def migrate_from_main_db(self, dataset_ids: List[str] = None) -> Dict[str, int]:
        """ä»ä¸»æ•°æ®åº“è¿ç§»æ•°æ®åˆ°åˆ†åº“"""
        migration_stats = {}
        
        try:
            # ä»ä¸»æ•°æ®åº“è·å–æ‰€æœ‰factor_expressionsæ•°æ®
            with self.main_db.get_connection() as conn:
                if dataset_ids:
                    placeholders = ','.join(['?' for _ in dataset_ids])
                    cursor = conn.execute(f"""
                        SELECT dataset_id, region, step, expression 
                        FROM factor_expressions 
                        WHERE dataset_id IN ({placeholders})
                        ORDER BY dataset_id, created_at
                    """, dataset_ids)
                else:
                    cursor = conn.execute("""
                        SELECT dataset_id, region, step, expression 
                        FROM factor_expressions 
                        ORDER BY dataset_id, created_at
                    """)
                
                # æŒ‰æ•°æ®é›†åˆ†ç»„
                dataset_expressions = {}
                for row in cursor.fetchall():
                    dataset_id, region, step, expression = row
                    if dataset_id not in dataset_expressions:
                        dataset_expressions[dataset_id] = []
                    dataset_expressions[dataset_id].append((expression, region, step))
                
                # è¿ç§»åˆ°å¯¹åº”åˆ†åº“
                for dataset_id, expressions in dataset_expressions.items():
                    print(f"ğŸ”„ è¿ç§»æ•°æ®é›† {dataset_id}: {len(expressions)} æ¡è®°å½•")
                    
                    with self._get_partition_connection(dataset_id) as partition_conn:
                        data = [(expr, dataset_id, region, step) for expr, region, step in expressions]
                        cursor = partition_conn.executemany("""
                            INSERT OR IGNORE INTO factor_expressions 
                            (expression, dataset_id, region, step) 
                            VALUES (?, ?, ?, ?)
                        """, data)
                        partition_conn.commit()
                        migration_stats[dataset_id] = cursor.rowcount
                        print(f"âœ… æ•°æ®é›† {dataset_id} è¿ç§»å®Œæˆ: {cursor.rowcount} æ¡è®°å½•")
        
        except Exception as e:
            print(f"âŒ æ•°æ®è¿ç§»å¤±è´¥: {e}")
        
        return migration_stats
    
    def cleanup_main_db_expressions(self, dataset_ids: List[str] = None) -> int:
        """æ¸…ç†ä¸»æ•°æ®åº“ä¸­å·²è¿ç§»çš„factor_expressionsæ•°æ®"""
        try:
            with self.main_db.get_connection() as conn:
                if dataset_ids:
                    placeholders = ','.join(['?' for _ in dataset_ids])
                    cursor = conn.execute(f"""
                        DELETE FROM factor_expressions 
                        WHERE dataset_id IN ({placeholders})
                    """, dataset_ids)
                else:
                    cursor = conn.execute("DELETE FROM factor_expressions")
                
                conn.commit()
                deleted_count = cursor.rowcount
                print(f"âœ… ä¸»æ•°æ®åº“æ¸…ç†å®Œæˆ: åˆ é™¤ {deleted_count} æ¡è®°å½•")
                return deleted_count
        except Exception as e:
            print(f"âŒ ä¸»æ•°æ®åº“æ¸…ç†å¤±è´¥: {e}")
            return 0
    
    def close_all_connections(self):
        """å…³é—­æ‰€æœ‰åˆ†åº“è¿æ¥"""
        with self._global_lock:
            for conn in self._partition_connections.values():
                try:
                    conn.close()
                except:
                    pass
            self._partition_connections.clear()
            self._connection_locks.clear()
    
    # ä»£ç†ä¸»æ•°æ®åº“çš„å…¶ä»–æ–¹æ³•
    def __getattr__(self, name):
        """ä»£ç†åˆ°ä¸»æ•°æ®åº“ç®¡ç†å™¨çš„å…¶ä»–æ–¹æ³•"""
        return getattr(self.main_db, name)


# ä¾¿æ·å‡½æ•°
def create_partitioned_manager(db_path: str = None) -> PartitionedFactorManager:
    """åˆ›å»ºåˆ†åº“ç®¡ç†å™¨å®ä¾‹"""
    if db_path is None:
        # ä½¿ç”¨é»˜è®¤è·¯å¾„
        current_dir = os.path.dirname(__file__)
        db_path = os.path.join(current_dir, 'factors.db')
    
    return PartitionedFactorManager(db_path)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    manager = create_partitioned_manager()
    
    # æ˜¾ç¤ºåˆ†åº“ç»Ÿè®¡
    stats = manager.get_partition_stats()
    print("ğŸ“Š åˆ†åº“ç»Ÿè®¡ä¿¡æ¯:")
    for dataset_id, info in stats.items():
        if 'error' not in info:
            print(f"  {dataset_id}: {info['total_expressions']} æ¡è®°å½•, {info['db_size_mb']} MB")
        else:
            print(f"  {dataset_id}: é”™è¯¯ - {info['error']}")
