#!/usr/bin/env python3
"""
æŸ¥çœ‹å’Œåˆ†æå¤±è´¥çš„å› å­è¡¨è¾¾å¼
"""

import os
import sys
import argparse
import pandas as pd
import json
from typing import Optional

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from db_manager import FactorDatabaseManager

def view_failed_expressions(dataset_id: Optional[str] = None, 
                          region: Optional[str] = None,
                          step: Optional[int] = None,
                          failure_reason: Optional[str] = None,
                          limit: int = 50):
    """æŸ¥çœ‹å¤±è´¥çš„å› å­è¡¨è¾¾å¼"""
    
    # åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
    db_path = os.path.join(os.path.dirname(__file__), 'factors.db')
    db = FactorDatabaseManager(db_path)
    
    print("ğŸ” æŸ¥è¯¢å¤±è´¥çš„å› å­è¡¨è¾¾å¼...")
    print(f"ğŸ“Š è¿‡æ»¤æ¡ä»¶: dataset_id={dataset_id}, region={region}, step={step}")
    print(f"ğŸ“Š å¤±è´¥åŸå› : {failure_reason}")
    print(f"ğŸ“Š æ˜¾ç¤ºè®°å½•æ•°: {limit}")
    print("=" * 80)
    
    # è·å–å¤±è´¥è¡¨è¾¾å¼åˆ—è¡¨
    failed_expressions = db.get_failed_expressions(
        dataset_id=dataset_id,
        region=region,
        step=step,
        failure_reason=failure_reason,
        limit=limit
    )
    
    if not failed_expressions:
        print("âœ… æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¤±è´¥è¡¨è¾¾å¼è®°å½•")
        return
    
    # è½¬æ¢ä¸ºDataFrameä»¥ä¾¿æ›´å¥½åœ°æ˜¾ç¤º
    df = pd.DataFrame(failed_expressions)
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(failed_expressions)} æ¡å¤±è´¥è®°å½•:\n")
    
    # è§£æerror_detailsä¸­çš„messageä½œä¸ºä¸»è¦å¤±è´¥åŸå› 
    def extract_error_message(error_details):
        """ä»error_detailsä¸­æå–messageï¼ˆæ”¯æŒJSONå’ŒPython dictæ ¼å¼ï¼‰"""
        if not error_details:
            return "Unknown error"
        try:
            # é¦–å…ˆå°è¯•JSONè§£æ
            error_data = json.loads(error_details)
            return error_data.get('message', 'Unknown error')
        except (json.JSONDecodeError, TypeError):
            try:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨evalè§£æPythonå­—å…¸æ ¼å¼
                # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨evalæ˜¯å› ä¸ºæ•°æ®æ¥è‡ªå¯ä¿¡çš„æ•°æ®åº“
                if isinstance(error_details, str) and error_details.startswith('{'):
                    error_data = eval(error_details)
                    if isinstance(error_data, dict):
                        return error_data.get('message', 'Unknown error')
                # å¦‚æœå·²ç»æ˜¯å­—å…¸
                elif isinstance(error_details, dict):
                    return error_details.get('message', 'Unknown error')
            except:
                pass
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›åŸå§‹å­—ç¬¦ä¸²çš„å‰100ä¸ªå­—ç¬¦
            return str(error_details)[:100] if error_details else "Unknown error"
    
    # æ·»åŠ æå–çš„é”™è¯¯æ¶ˆæ¯åˆ—
    df['error_message'] = df['error_details'].apply(extract_error_message)
    
    # æŒ‰é”™è¯¯æ¶ˆæ¯åˆ†ç»„æ˜¾ç¤º
    for message in df['error_message'].unique():
        message_df = df[df['error_message'] == message]
        print(f"\nğŸ”¥ é”™è¯¯æ¶ˆæ¯: {message} ({len(message_df)} æ¡)")
        print("-" * 80)
        
        for idx, row in message_df.head(10).iterrows():  # æ¯ä¸ªé”™è¯¯æœ€å¤šæ˜¾ç¤º10æ¡
            print(f"ğŸ“… {row['created_at']}")
            print(f"ğŸ¯ æ•°æ®é›†: {row['dataset_id']} | åœ°åŒº: {row['region']} | æ­¥éª¤: {row['step']}")
            print(f"ğŸ“ è¡¨è¾¾å¼: {row['expression'][:120]}{'...' if len(row['expression']) > 120 else ''}")
            
            # æ˜¾ç¤ºå®Œæ•´çš„APIå“åº”ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if row['error_details']:
                try:
                    error_data = json.loads(row['error_details'])
                    if 'id' in error_data:
                        print(f"ğŸ”— æ¨¡æ‹ŸID: {error_data['id']}")
                    if 'type' in error_data:
                        print(f"ğŸ“Š ç±»å‹: {error_data['type']}")
                    if 'status' in error_data:
                        print(f"âš ï¸  çŠ¶æ€: {error_data['status']}")
                except (json.JSONDecodeError, TypeError):
                    print(f"ğŸ’¬ åŸå§‹é”™è¯¯: {row['error_details'][:150]}{'...' if len(str(row['error_details'])) > 150 else ''}")
            print()
        
        if len(message_df) > 10:
            print(f"   ... è¿˜æœ‰ {len(message_df) - 10} æ¡è®°å½•ï¼ˆä½¿ç”¨ --limit å‚æ•°æŸ¥çœ‹æ›´å¤šï¼‰")

def show_failure_stats():
    """æ˜¾ç¤ºå¤±è´¥ç»Ÿè®¡ä¿¡æ¯"""
    
    # åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
    db_path = os.path.join(os.path.dirname(__file__), 'factors.db')
    db = FactorDatabaseManager(db_path)
    
    print("ğŸ“Š å¤±è´¥è¡¨è¾¾å¼ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 60)
    
    # è·å–æ‰€æœ‰å¤±è´¥è¡¨è¾¾å¼è¿›è¡Œè‡ªå®šä¹‰ç»Ÿè®¡
    failed_expressions = db.get_failed_expressions(limit=10000)
    
    if not failed_expressions:
        print("âœ… æ²¡æœ‰æ‰¾åˆ°å¤±è´¥è¡¨è¾¾å¼è®°å½•")
        return
    
    df = pd.DataFrame(failed_expressions)
    
    # è§£æerror_detailsä¸­çš„message
    def extract_error_message(error_details):
        if not error_details:
            return "Unknown error"
        try:
            # é¦–å…ˆå°è¯•JSONè§£æ
            error_data = json.loads(error_details)
            return error_data.get('message', 'Unknown error')
        except (json.JSONDecodeError, TypeError):
            try:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨evalè§£æPythonå­—å…¸æ ¼å¼
                if isinstance(error_details, str) and error_details.startswith('{'):
                    error_data = eval(error_details)
                    if isinstance(error_data, dict):
                        return error_data.get('message', 'Unknown error')
                # å¦‚æœå·²ç»æ˜¯å­—å…¸
                elif isinstance(error_details, dict):
                    return error_details.get('message', 'Unknown error')
            except:
                pass
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›åŸå§‹å­—ç¬¦ä¸²çš„å‰100ä¸ªå­—ç¬¦
            return str(error_details)[:100] if error_details else "Unknown error"
    
    df['error_message'] = df['error_details'].apply(extract_error_message)
    
    print(f"ğŸ”¢ æ€»å¤±è´¥è®°å½•æ•°: {len(df)}")
    print(f"ğŸ”¢ å”¯ä¸€å¤±è´¥è¡¨è¾¾å¼æ•°: {df['expression'].nunique()}")
    
    # æœ€è¿‘24å°æ—¶çš„å¤±è´¥æ•°
    recent_failures = len(df[df['created_at'] >= (pd.Timestamp.now() - pd.Timedelta(hours=24)).strftime('%Y-%m-%d %H:%M:%S')])
    print(f"ğŸ”¢ æœ€è¿‘24å°æ—¶å¤±è´¥æ•°: {recent_failures}")
    
    print("\nğŸ“‹ æŒ‰å…·ä½“é”™è¯¯æ¶ˆæ¯ç»Ÿè®¡ (Top 10):")
    error_message_stats = df.groupby('error_message').agg({
        'expression': ['count', 'nunique'],
        'dataset_id': 'nunique'
    }).round(2)
    error_message_stats.columns = ['total_count', 'unique_expressions', 'affected_datasets']
    error_message_stats = error_message_stats.sort_values('total_count', ascending=False).head(10)
    
    for error_msg, row in error_message_stats.iterrows():
        # ç¡®ä¿é”™è¯¯æ¶ˆæ¯ä¸è¢«æˆªæ–­
        display_msg = error_msg if len(error_msg) <= 80 else error_msg[:77] + "..."
        print(f"   {display_msg}: {int(row['total_count'])} æ¬¡, {int(row['unique_expressions'])} ä¸ªå”¯ä¸€è¡¨è¾¾å¼, {int(row['affected_datasets'])} ä¸ªæ•°æ®é›†")
    
    print("\nğŸ“‹ æŒ‰æ•°æ®é›†ç»Ÿè®¡ (Top 10):")
    dataset_stats = df.groupby(['dataset_id', 'region', 'step']).agg({
        'expression': ['count', 'nunique'],
        'error_message': 'nunique'
    }).round(2)
    dataset_stats.columns = ['total_count', 'unique_expressions', 'failure_types']
    dataset_stats = dataset_stats.sort_values('total_count', ascending=False).head(10)
    
    for (dataset_id, region, step), row in dataset_stats.iterrows():
        print(f"   {dataset_id} ({region}, Step {step}): {int(row['total_count'])} æ¬¡å¤±è´¥, {int(row['unique_expressions'])} ä¸ªå”¯ä¸€è¡¨è¾¾å¼, {int(row['failure_types'])} ç§å¤±è´¥ç±»å‹")
    
    print("\nğŸ“Š è¡¨è¾¾å¼é•¿åº¦ç»Ÿè®¡:")
    expr_lengths = df['expression'].str.len()
    print(f"   å¹³å‡é•¿åº¦: {expr_lengths.mean():.1f} å­—ç¬¦")
    print(f"   æœ€çŸ­é•¿åº¦: {expr_lengths.min()} å­—ç¬¦") 
    print(f"   æœ€é•¿é•¿åº¦: {expr_lengths.max()} å­—ç¬¦")
    
    print("\nğŸ” æœ€å¸¸è§çš„é”™è¯¯æ¨¡å¼:")
    # åˆ†æé”™è¯¯æ¶ˆæ¯çš„æ¨¡å¼
    error_patterns = {}
    for msg in df['error_message'].unique():
        if 'Invalid data field' in msg:
            error_patterns['Invalid data field'] = error_patterns.get('Invalid data field', 0) + len(df[df['error_message'] == msg])
        elif 'syntax' in msg.lower():
            error_patterns['Syntax error'] = error_patterns.get('Syntax error', 0) + len(df[df['error_message'] == msg])
        elif 'undefined' in msg.lower() or 'unknown' in msg.lower():
            error_patterns['Undefined/Unknown'] = error_patterns.get('Undefined/Unknown', 0) + len(df[df['error_message'] == msg])
        elif 'end of input' in msg.lower():
            error_patterns['Unexpected end of input'] = error_patterns.get('Unexpected end of input', 0) + len(df[df['error_message'] == msg])
        else:
            error_patterns['Other'] = error_patterns.get('Other', 0) + len(df[df['error_message'] == msg])
    
    for pattern, count in sorted(error_patterns.items(), key=lambda x: x[1], reverse=True):
        percentage = (count / len(df)) * 100
        print(f"   {pattern}: {count} æ¬¡ ({percentage:.1f}%)")

def export_failed_expressions(output_file: str, **filters):
    """å¯¼å‡ºå¤±è´¥è¡¨è¾¾å¼åˆ°CSVæ–‡ä»¶"""
    
    # åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
    db_path = os.path.join(os.path.dirname(__file__), 'factors.db')
    db = FactorDatabaseManager(db_path)
    
    print(f"ğŸ“¤ å¯¼å‡ºå¤±è´¥è¡¨è¾¾å¼åˆ° {output_file}...")
    
    # è·å–æ‰€æœ‰å¤±è´¥è¡¨è¾¾å¼ï¼ˆä¸é™åˆ¶æ•°é‡ï¼‰
    failed_expressions = db.get_failed_expressions(limit=10000, **filters)
    
    if not failed_expressions:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¤±è´¥è¡¨è¾¾å¼è®°å½•")
        return
    
    # è½¬æ¢ä¸ºDataFrameå¹¶è§£æé”™è¯¯æ¶ˆæ¯
    df = pd.DataFrame(failed_expressions)
    
    # è§£æerror_detailsä¸­çš„message
    def extract_error_message(error_details):
        if not error_details:
            return "Unknown error"
        try:
            # é¦–å…ˆå°è¯•JSONè§£æ
            error_data = json.loads(error_details)
            return error_data.get('message', 'Unknown error')
        except (json.JSONDecodeError, TypeError):
            try:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨evalè§£æPythonå­—å…¸æ ¼å¼
                if isinstance(error_details, str) and error_details.startswith('{'):
                    error_data = eval(error_details)
                    if isinstance(error_data, dict):
                        return error_data.get('message', 'Unknown error')
                # å¦‚æœå·²ç»æ˜¯å­—å…¸
                elif isinstance(error_details, dict):
                    return error_details.get('message', 'Unknown error')
            except:
                pass
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›åŸå§‹å­—ç¬¦ä¸²çš„å‰100ä¸ªå­—ç¬¦
            return str(error_details)[:100] if error_details else "Unknown error"
    
    def extract_simulation_id(error_details):
        if not error_details:
            return ""
        try:
            # é¦–å…ˆå°è¯•JSONè§£æ
            error_data = json.loads(error_details)
            return error_data.get('id', '')
        except (json.JSONDecodeError, TypeError):
            try:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨evalè§£æPythonå­—å…¸æ ¼å¼
                if isinstance(error_details, str) and error_details.startswith('{'):
                    error_data = eval(error_details)
                    if isinstance(error_data, dict):
                        return error_data.get('id', '')
                # å¦‚æœå·²ç»æ˜¯å­—å…¸
                elif isinstance(error_details, dict):
                    return error_details.get('id', '')
            except:
                pass
            return ""
    
    # æ·»åŠ è§£æåçš„åˆ—
    df['error_message'] = df['error_details'].apply(extract_error_message)
    df['simulation_id'] = df['error_details'].apply(extract_simulation_id)
    
    # é‡æ–°æ’åˆ—åˆ—é¡ºåºï¼Œå°†é‡è¦ä¿¡æ¯æ”¾åœ¨å‰é¢
    column_order = ['created_at', 'dataset_id', 'region', 'step', 'error_message', 
                    'expression', 'failure_reason', 'simulation_id', 'error_details']
    df = df.reindex(columns=column_order)
    
    df.to_csv(output_file, index=False, encoding='utf-8')
    
    print(f"âœ… æˆåŠŸå¯¼å‡º {len(failed_expressions)} æ¡è®°å½•åˆ° {output_file}")
    print(f"ğŸ“‹ å¯¼å‡ºæ–‡ä»¶åŒ…å«ä»¥ä¸‹åˆ—: {', '.join(df.columns.tolist())}")

def cleanup_old_failures(days: int = 30):
    """æ¸…ç†æ—§çš„å¤±è´¥è®°å½•"""
    
    # åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
    db_path = os.path.join(os.path.dirname(__file__), 'factors.db')
    db = FactorDatabaseManager(db_path)
    
    print(f"ğŸ§¹ æ¸…ç† {days} å¤©å‰çš„å¤±è´¥è®°å½•...")
    
    deleted_count = db.cleanup_old_failed_expressions(days)
    
    print(f"âœ… å·²æ¸…ç† {deleted_count} æ¡æ—§è®°å½•")

def main():
    parser = argparse.ArgumentParser(description='æŸ¥çœ‹å’Œåˆ†æå¤±è´¥çš„å› å­è¡¨è¾¾å¼')
    parser.add_argument('--action', choices=['view', 'stats', 'export', 'cleanup'], 
                       default='view', help='æ“ä½œç±»å‹')
    parser.add_argument('--dataset-id', help='æ•°æ®é›†IDè¿‡æ»¤')
    parser.add_argument('--region', help='åœ°åŒºè¿‡æ»¤')
    parser.add_argument('--step', type=int, help='æ­¥éª¤è¿‡æ»¤')
    parser.add_argument('--failure-reason', help='å¤±è´¥åŸå› è¿‡æ»¤')
    parser.add_argument('--limit', type=int, default=50, help='æ˜¾ç¤ºè®°å½•æ•°é™åˆ¶')
    parser.add_argument('--output', help='å¯¼å‡ºæ–‡ä»¶è·¯å¾„ (ç”¨äºexport)')
    parser.add_argument('--days', type=int, default=30, help='æ¸…ç†å¤©æ•° (ç”¨äºcleanup)')
    
    args = parser.parse_args()
    
    if args.action == 'view':
        view_failed_expressions(
            dataset_id=args.dataset_id,
            region=args.region,
            step=args.step,
            failure_reason=args.failure_reason,
            limit=args.limit
        )
    elif args.action == 'stats':
        show_failure_stats()
    elif args.action == 'export':
        if not args.output:
            print("âŒ å¯¼å‡ºæ“ä½œéœ€è¦æŒ‡å®š --output å‚æ•°")
            return
        export_failed_expressions(
            args.output,
            dataset_id=args.dataset_id,
            region=args.region,
            step=args.step,
            failure_reason=args.failure_reason
        )
    elif args.action == 'cleanup':
        cleanup_old_failures(args.days)

if __name__ == '__main__':
    main()
