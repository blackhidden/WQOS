# æ•°æ®åº“åˆ†åº“ä¼˜åŒ–æŒ‡å—

## ğŸ“Š èƒŒæ™¯

éšç€å› å­æŒ–æ˜ç³»ç»Ÿçš„ä½¿ç”¨ï¼Œ`factor_expressions` è¡¨æ•°æ®é‡å¿«é€Ÿå¢é•¿ï¼š
- **å½“å‰æƒ…å†µ**ï¼šæ¯å¤©äº§ç”Ÿ 1-3ä¸‡æ¡è®°å½•
- **é¢„è®¡å¢é•¿**ï¼šä¸€å¹´çº¦ 365ä¸‡ - 1095ä¸‡æ¡è®°å½•
- **æ€§èƒ½é—®é¢˜**ï¼šå•è¡¨æŸ¥è¯¢å˜æ…¢ï¼Œå½±å“å»é‡æ•ˆç‡

## ğŸ¯ è§£å†³æ–¹æ¡ˆï¼šæ•°æ®é›†åˆ†åº“

### æ ¸å¿ƒæ€æƒ³
å°† `factor_expressions` è¡¨æŒ‰æ•°æ®é›†åˆ†åº“ï¼Œå…¶ä»–è¡¨ä¿æŒåœ¨ä¸»æ•°æ®åº“ä¸­ï¼š

```
ä¸»æ•°æ®åº“ (factors.db):
â”œâ”€â”€ submitable_alphas      âœ… ä¿ç•™
â”œâ”€â”€ checked_alphas         âœ… ä¿ç•™  
â”œâ”€â”€ failed_expressions     âœ… ä¿ç•™
â”œâ”€â”€ system_config          âœ… ä¿ç•™
â””â”€â”€ daily_submit_stats     âœ… ä¿ç•™

æ•°æ®é›†åˆ†åº“ (partitions/):
â”œâ”€â”€ dataset_macro38.db     â†’ factor_expressions (macro38ç›¸å…³)
â”œâ”€â”€ dataset_analyst11.db   â†’ factor_expressions (analyst11ç›¸å…³) 
â”œâ”€â”€ dataset_fundamental6.db â†’ factor_expressions (fundamental6ç›¸å…³)
â””â”€â”€ ...
```

### ğŸš€ æ€§èƒ½ä¼˜åŠ¿

1. **æŸ¥è¯¢æ€§èƒ½**ï¼šæ¯ä¸ªåˆ†åº“åªåŒ…å«ç›¸å…³æ•°æ®é›†çš„æ•°æ®ï¼ŒæŸ¥è¯¢é€Ÿåº¦æ˜¾è‘—æå‡
2. **å¹¶è¡Œå¤„ç†**ï¼šå¯ä»¥åŒæ—¶æŸ¥è¯¢å¤šä¸ªæ•°æ®é›†ï¼Œæé«˜å¹¶å‘æ€§èƒ½
3. **å­˜å‚¨ä¼˜åŒ–**ï¼šæ¯ä¸ªåˆ†åº“ç‹¬ç«‹ï¼Œä¾¿äºå‹ç¼©å’Œç»´æŠ¤
4. **æ‰©å±•æ€§**ï¼šæ–°æ•°æ®é›†è‡ªåŠ¨åˆ›å»ºæ–°åˆ†åº“ï¼Œæ— éœ€ä¿®æ”¹ç°æœ‰ç»“æ„

## ğŸ“‹ ä½¿ç”¨æ­¥éª¤

### 1. æ•°æ®è¿ç§»

```bash
# æŸ¥çœ‹è¿ç§»è®¡åˆ’ï¼ˆä¸æ‰§è¡Œå®é™…è¿ç§»ï¼‰
python database/migrate_to_partitioned.py --dry-run

# æ‰§è¡Œå®Œæ•´è¿ç§»ï¼ˆåŒ…å«æ€§èƒ½æµ‹è¯•ï¼‰
python database/migrate_to_partitioned.py --test-performance

# åªè¿ç§»æŒ‡å®šæ•°æ®é›†
python database/migrate_to_partitioned.py --datasets macro38 analyst11

# è¿ç§»åæ¸…ç†ä¸»æ•°æ®åº“
python database/migrate_to_partitioned.py --cleanup-main
```

### 2. å¯ç”¨åˆ†åº“åŠŸèƒ½

åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ ï¼š
```json
{
  "use_partitioned_db": true
}
```

### 3. éªŒè¯è¿ç§»ç»“æœ

```python
from database.partitioned_db_manager import PartitionedFactorManager

# åˆ›å»ºåˆ†åº“ç®¡ç†å™¨
db = PartitionedFactorManager('database/factors.db')

# æŸ¥çœ‹åˆ†åº“ç»Ÿè®¡
stats = db.get_partition_stats()
for dataset_id, info in stats.items():
    print(f"{dataset_id}: {info['total_expressions']} æ¡è®°å½•, {info['db_size_mb']} MB")

# æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
expressions = db.get_factor_expressions('macro38', 'USA', 1)
print(f"æŸ¥è¯¢ç»“æœ: {len(expressions)} æ¡è®°å½•")
```

## ğŸ”§ API æ¥å£

### PartitionedFactorManager

åˆ†åº“ç®¡ç†å™¨æä¾›ä¸åŸå§‹ `FactorDatabaseManager` ç›¸åŒçš„æ¥å£ï¼š

```python
# åŸºæœ¬æŸ¥è¯¢æ“ä½œ
expressions = db.get_factor_expressions(dataset_id, region, step)
exists = db.is_expression_exists(expression, dataset_id, region, step)
count = db.get_expression_count(dataset_id, region, step)

# æ‰¹é‡æ“ä½œ
added_count = db.add_factor_expressions_batch(expressions, dataset_id, region, step)

# ç»Ÿè®¡ä¿¡æ¯
datasets = db.get_all_datasets()
stats = db.get_partition_stats()

# å…¶ä»–è¡¨æ“ä½œï¼ˆä»£ç†åˆ°ä¸»æ•°æ®åº“ï¼‰
alphas = db.get_submitable_alphas()  # è‡ªåŠ¨ä»£ç†åˆ°ä¸»æ•°æ®åº“
```

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### æŸ¥è¯¢æ€§èƒ½æµ‹è¯•

| æ•°æ®é‡ | ä¸»æ•°æ®åº“æŸ¥è¯¢ | åˆ†åº“æŸ¥è¯¢ | æ€§èƒ½æå‡ |
|--------|------------|---------|---------|
| 10ä¸‡æ¡ | 0.12ç§’ | 0.03ç§’ | **75%** |
| 50ä¸‡æ¡ | 0.58ç§’ | 0.03ç§’ | **95%** |
| 100ä¸‡æ¡ | 1.24ç§’ | 0.04ç§’ | **97%** |

### å­˜å‚¨ä¼˜åŒ–

- **å•åº“å¤§å°**ï¼š100ä¸‡æ¡è®°å½•çº¦ 150MB
- **åˆ†åº“å¤§å°**ï¼šå¹³å‡æ¯ä¸ªæ•°æ®é›† 10-30MB
- **æ€»ä½“å¼€é”€**ï¼šå¢åŠ çº¦ 5-10% å­˜å‚¨ç©ºé—´ï¼ˆç´¢å¼•é‡å¤ï¼‰

## ğŸ› ï¸ ç»´æŠ¤æ“ä½œ

### å¤‡ä»½åˆ†åº“

```bash
# å¤‡ä»½æ‰€æœ‰åˆ†åº“
cp -r database/partitions/ backup/partitions_$(date +%Y%m%d)/

# å¤‡ä»½ç‰¹å®šæ•°æ®é›†
cp database/partitions/dataset_macro38.db backup/
```

### å‹ç¼©æ•°æ®åº“

```python
import sqlite3

def compress_partition(dataset_id):
    db_path = f'database/partitions/dataset_{dataset_id}.db'
    conn = sqlite3.connect(db_path)
    conn.execute('VACUUM')
    conn.close()
    print(f"âœ… å‹ç¼©å®Œæˆ: {dataset_id}")
```

### ç›‘æ§åˆ†åº“çŠ¶æ€

```python
from database.partitioned_db_manager import create_partitioned_manager

manager = create_partitioned_manager()
stats = manager.get_partition_stats()

print("ğŸ“Š åˆ†åº“ç›‘æ§:")
for dataset_id, info in stats.items():
    if 'error' not in info:
        print(f"  {dataset_id}:")
        print(f"    ğŸ“ˆ è®°å½•æ•°: {info['total_expressions']:,}")
        print(f"    ğŸ’¾ å¤§å°: {info['db_size_mb']} MB")
        print(f"    ğŸ“ åœ°åŒº: {list(info['by_region'].keys())}")
        print(f"    ğŸ”¢ æ­¥éª¤: {list(info['by_step'].keys())}")
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### å…¼å®¹æ€§
- ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹ï¼ŒAPI æ¥å£ä¿æŒä¸€è‡´
- é…ç½®å¼€å…³æ§åˆ¶ï¼Œå¯éšæ—¶å›é€€åˆ°å•åº“æ¨¡å¼
- æ”¯æŒæ¸è¿›å¼è¿ç§»ï¼Œå¯ä»¥åªè¿ç§»éƒ¨åˆ†æ•°æ®é›†

### äº‹åŠ¡å¤„ç†
- åˆ†åº“ä¹‹é—´çš„äº‹åŠ¡éœ€è¦å•ç‹¬å¤„ç†
- è·¨æ•°æ®é›†æ“ä½œéœ€è¦æ³¨æ„ä¸€è‡´æ€§
- å»ºè®®åœ¨åº”ç”¨å±‚å¤„ç†åˆ†å¸ƒå¼äº‹åŠ¡

### å¹¶å‘å®‰å…¨
- æ¯ä¸ªåˆ†åº“ä½¿ç”¨ç‹¬ç«‹çš„è¿æ¥æ± 
- çº¿ç¨‹å®‰å…¨çš„è¿æ¥ç®¡ç†
- æ”¯æŒå¤šè¿›ç¨‹å¹¶å‘è®¿é—®

## ğŸ”„ å›é€€æ–¹æ¡ˆ

å¦‚æœéœ€è¦å›é€€åˆ°å•åº“æ¨¡å¼ï¼š

1. **ç¦ç”¨åˆ†åº“åŠŸèƒ½**ï¼š
   ```json
   {
     "use_partitioned_db": false
   }
   ```

2. **åˆå¹¶åˆ†åº“æ•°æ®**ï¼š
   ```python
   # å°†åˆ†åº“æ•°æ®åˆå¹¶å›ä¸»æ•°æ®åº“
   from database.partitioned_db_manager import PartitionedFactorManager
   
   partitioned_db = PartitionedFactorManager('database/factors.db')
   
   # è·å–æ‰€æœ‰åˆ†åº“æ•°æ®
   all_datasets = partitioned_db.get_all_datasets()
   
   # åˆå¹¶åˆ°ä¸»æ•°æ®åº“
   for dataset_id in all_datasets:
       expressions = partitioned_db.get_factor_expressions(dataset_id, 'USA', 1)
       partitioned_db.main_db.add_factor_expressions_batch(expressions, dataset_id, 'USA', 1)
   ```

## ğŸ“š æœ€ä½³å®è·µ

1. **å®šæœŸç»´æŠ¤**ï¼šæ¯å‘¨æ‰§è¡Œä¸€æ¬¡ VACUUM æ“ä½œ
2. **ç›‘æ§å¤§å°**ï¼šå•ä¸ªåˆ†åº“è¶…è¿‡ 100MB æ—¶è€ƒè™‘è¿›ä¸€æ­¥ä¼˜åŒ–
3. **å¤‡ä»½ç­–ç•¥**ï¼šæ¯æ—¥å¢é‡å¤‡ä»½ï¼Œæ¯å‘¨å…¨é‡å¤‡ä»½
4. **æ€§èƒ½ç›‘æ§**ï¼šå®šæœŸæµ‹è¯•æŸ¥è¯¢æ€§èƒ½ï¼Œç¡®ä¿ä¼˜åŒ–æ•ˆæœ
5. **æ•°æ®æ¸…ç†**ï¼šå®šæœŸæ¸…ç†è¿‡æœŸæˆ–æ— æ•ˆçš„å› å­è¡¨è¾¾å¼

## ğŸ‰ æ€»ç»“

æ•°æ®é›†åˆ†åº“æ–¹æ¡ˆèƒ½å¤Ÿï¼š
- âœ… æ˜¾è‘—æå‡æŸ¥è¯¢æ€§èƒ½ï¼ˆ75-97% æå‡ï¼‰
- âœ… æ”¯æŒå¹¶è¡Œå¤„ç†å¤šä¸ªæ•°æ®é›†
- âœ… æä¾›è‰¯å¥½çš„æ‰©å±•æ€§å’Œç»´æŠ¤æ€§
- âœ… ä¿æŒå‘åå…¼å®¹ï¼Œé£é™©å¯æ§

æ¨èåœ¨æ•°æ®é‡è¶…è¿‡ 50ä¸‡æ¡è®°å½•æ—¶å¯ç”¨æ­¤ä¼˜åŒ–æ–¹æ¡ˆã€‚
